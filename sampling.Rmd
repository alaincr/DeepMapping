---
title: "Supplementary Information for Deep Mapping Gentrification: Using a deep convolutional neural network and Google Street View to map the spatial and temporal evolution of gentrification-like visual changes in a large Canadian City."
author: "Lazar Ilic, M. Sawada, Amaury Zarzelli"
output:
  output:
  bookdown::pdf_document2
fontsize: 12pt
header-includes: 
     \newcommand{\beginsupplement}{
    \setcounter{table}{0}  
    \renewcommand{\thetable}{S\arabic{table}} 
    \setcounter{figure}{0} 
    \renewcommand{\thefigure}{S\arabic{figure}}}
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    latex_engine: lualatex
    number_sections: yes
    toc: yes
  html_document:
    df_print: paged
    fig_caption: yes
  word_document: 
    fig_caption: yes
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
use_python("c:/programdata/anaconda3/python.exe")
pdf.options(encoding = 'CP1250')
```



```{r message=FALSE, echo=FALSE}
#Import required libraries
library(spatstat)
library(maptools)
library(stringr)
library(raster)
library(dplyr)
library(classInt)
library(rgdal)
library(fields)
library(Hmisc)
library(RColorBrewer)
library(rgeos)
```

```{r functions, echo=FALSE}
###Functions
ptDensity = function(a, sarea,res=200) {
  # Calculate KDE
  kdepredict = density.ppp(as.ppp(a),
  eps = res,
  kernel = 'gaussian',
  sigma = 200)
  kdepredict = raster(kdepredict)
  kdepredict <- crop(kdepredict, extent(sarea))
  kdepredict <- raster::mask(kdepredict, sarea)
  return(kdepredict)
}


densBreaks = function(kdepredict,n,style) {
  if(!(is.numeric(kdepredict)=="numeric")) {
    vals = values(kdepredict)
  vals = vals[!is.na(vals)]
  }
  else{vals=kdepredict}
  cint = classIntervals(vals, n = n, style = style)
  return(cint)
}

openSPDF = function(shapefilepath,outCS=CRS("+init=epsg:32189")) {
  permitpts.b=readOGR(shapefilepath,verbose=FALSE)#,stringsAsFactors = FALSE)
  # arc.check_product()
  permits = spTransform(permitpts.b, outCS)
  return(permits)
}
```

```{r trainingdata, echo=FALSE,message=FALSE}
#Open training data file "retrain.txt", get coordinates, create spdf, project to mtm9. Also open studyarea polygons.
# Get training data list
x = read.delim("./rproject/retrain.txt",sep = " ",header = FALSE)

ll = lapply(str_split(x[, 1], "/"), function(x)
  x[4])
yy = unlist(lapply(str_split(ll, ","), function(x)
  x[1]))
xx = unlist(lapply(str_split(ll, ","), function(x)
  x[2]))

yy = unlist(lapply(str_split(yy, "new-"), function(x) {
  if (length(x) == 2) {
    x[2]
  }
  else{
    x[1]
  }
}))

# Check for NA
#yy[is.na(as.numeric(yy))]


xx = unlist(lapply(str_split(xx, "new-"), function(x) {
  if (length(x) == 2) {
    x[2]
  }
  else{
    x[1]
  }
}))

# Check for NA
#xx[is.na(as.numeric(xx))]


# put x,y into x dataframe for coordinates of each pair

x$Long = xx
x$Lat = yy
x = x[which(x$V3 != "np"),]
x = x[which(x$V3 != "nof"),]

# Remove nonused levels of factors (3 or 4 bad rows)
x = droplevels(x)

#
# Make spdf of training data duels file

spd = SpatialPointsDataFrame(cbind(x = as.numeric(x$Long), y = as.numeric(x$Lat)), x)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spd) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spd = spTransform(spd, srMTM9)

# Read in the replicated model run
x1=read.csv("./rproject/fullres_replicate.csv")
x1=x1[x1$PRED==1,]

spdrep = SpatialPointsDataFrame(cbind(x = as.numeric(x1$LONG), y = as.numeric(x1$LAT)), x1)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spdrep) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spdrep = spTransform(spdrep, srMTM9)

# Read in the original model run

xo=read.csv("./rproject/fullres.csv")
xo=xo[xo$PRED==1,]

spdo = SpatialPointsDataFrame(cbind(x = as.numeric(xo$LONG), y = as.numeric(xo$LAT)), xo)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spdo) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spdo = spTransform(spdo, srMTM9)

#Load GSV dates, create SPDF, assign and project.

# Get GSV date list
x = read.delim("./rproject/GSVDATESSPAN.csv",sep = ",",header = TRUE)
#names(x)=c("LAT","LONOG","OLDEST","YOUNGEST","SPAN")
# Make spdf of training data duels fi


gsvdates = SpatialPointsDataFrame(cbind(x = x$LON, y = x$LAT), x)

# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates = spTransform(gsvdates, srMTM9)


# Make unique point file for probabilities
#spdU=remove.duplicates(spd)

# Open study area mask, convert to spdf and reproject to MTM9
m4 = openSPDF(shapefilepath = './shapefiles/core_multi.shp')

permits=openSPDF(shapefilepath = './shapefiles/permits.shp')

options(stringsAsFactors = FALSE)
predpts=openSPDF(shapefilepath = './shapefiles/predicted.shp')
predpts@data$YEAR1=as.numeric(predpts@data$YEAR1)
predpts@data$YEAR2=as.numeric(predpts@data$YEAR2)
predpts@data$PRED=as.numeric(predpts@data$PRED)
options(stringsAsFactors = TRUE)

predptso=predpts
# Get predictions after 2011
predpts=remove.duplicates(predpts,remove.second = F)

studyarea=openSPDF(shapefilepath = './shapefiles/core_multi.shp')

nbrhoods=openSPDF(shapefilepath = './shapefiles/core.shp')

ons=openSPDF(shapefilepath='./shapefiles/ONSNeighbourhoods2012_SmallFile.shp')

outercore=openSPDF(shapefilepath = './shapefiles/outercore.shp')
outercore$DID=rep(1,length(outercore$OBJECTID))
region <- gUnaryUnion(outercore, id = outercore@data$DID)

labelhoods=openSPDF(shapefilepath = './shapefiles/labelhoods.shp')
labelhoods@data$names=as.character(labelhoods@data$names)
labelhoods@data$names[3]="Crestview\nMeadowlands"
labelhoods@data$names[4]="Hintonburg\nMechanicsville"
labelhoods@data$names[5]="Island\nPark"


```

```{python py, echo=FALSE, eval=FALSE}
import glob
import os
basedir='f:/ottawa_image_db/'
dirlist = os.listdir(basedir)

with open("f:/models/ffxx.csv", "w") as f:
    f.write("LAT,LON,MINY,MAXY,DRANGE,NPHOTO,NYEARS\n")
    for d in dirlist:
        images = glob.glob(basedir+d+ '/*.jpg')
        if len(images)!=0:
            dlist=[]
            for image in images:
                fn=os.path.basename(image)
                dlist.append(fn[0:4])
            mx=max(dlist)
            mn=min(dlist)
            diff=int(mx)-int(mn)
            ld=len(dlist)
            lds=len(set(dlist))
            f.write("{},{},{},{},{},{}\n".format(d, mn,mx,diff,ld,lds))
            #print(dlist,min(dlist))

# All years for all images
with open("f:/models/allyearvector.csv", "w") as f:
    #f.write("LAT,LON,MINY,MAXY,DRANGE,NPHOTO,NYEARS\n")
    for d in dirlist:
        images = glob.glob(basedir+d+ '/*.jpg')
        if len(images)!=0:
            dlist=[]
            for image in images:
                fn=os.path.basename(image)
                dlist.append(fn[0:4])
                f.write("{}\n".format(fn[0:4]))
                
# locations ith a date in 2007 and a date in 2014-2016.                
with open("f:/models/ff_old_young2.csv", "w") as f:
    f.write("LAT,LON,MINY,MAXY,DRANGE,NPHOTO,NYEARS\n")
    for d in dirlist:
        images = glob.glob(basedir+d+ '/*.jpg')
        if len(images)!=0:
            dlist=[]
            fnamelist=[]
            for image in images:
                fn=os.path.basename(image)
                fnamelist.append(fn)
                dlist.append(fn[0:4])
            mx=max(dlist)
            mn=min(dlist)
            diff=int(mx)-int(mn)
            ld=len(dlist)
            lds=len(set(dlist))
            if (((mx=='2016') | (mx=='2015') | (mx=='2014')) & (mn=='2007')):
                f.write("{},{},{},{},{},{}\n".format(d, mn,mx,diff,ld,lds))
            #print(dlist,min(dlist))
```

#Introduction
We use SCNN-FC-8 to detect gentrification-like visual changes within the sequence of GSV images for a property.   Subsequently, we map the locations of GSV panoramas within which a change was detected. 

#Github repository
The python programmes used to create and train SCNN-FC-8 can be found at: https://github.com/laggiss/DeepMapping. 

>**NOTE**: *This document was created from an RMarkdown file.  The RMarkdown version of this doucument contains all of the R-language code used to access datasets as well as create the maps (except Figure 1 in the manuscript which was created elsewhere) and graphs in this supplementary document and manuscript. However, the R code is suppressed in the version you are currently reading.  Should you wish to examine the raw data or code, you can find the RMarkdown document with R-language code containing all references at (https://github.com/laggiss/DeepMapping/blob/master/sampling.Rmd)*.

#Study area and GSV data
The spatio-temporal coverage of GSV imagery varies across space and time. We were primarily concerned with detecting gentrification as far back as possible within our 'study area'.  The study area corresponds to the spatial domain defined by the highest concentration of older building stock in Ottawa (see Figure 1 in manuscript).  To train SCNN-FC-8, we wanted a larger region in which to find examples of gentrification-like visual change.  Thus, we accessed GSV imagery within a broader region that includes our study area and a buffer region that, itself, is comprised primarily of post 1980's suburban residential land use.  We call this broader region the 'GSV access region' within which panoramas were selected to train SCNN-FC-8 (Figure S\ref{fig:allgsvdata}a).  There were `r length(gsvdates)` properties containing panoramas within the GSV access region.  Because each property/location can have numerous panormamas over time, the total number of panormams across the properties was 593,723.  A subset of 16224 GSV panoramas used for training, validating and testing SCNN-FC-8 (Figure S\ref{fig:allgsvdata}b).

```{r allgsvdata, message=F,echo=FALSE,fig.width=7,fig.height=3.5,fig.cap="\\label{fig:allgsvdata}a) Distribution of all GSV panormas accessed in this research; b) Subset of GSV panoramas within the GSV access area that were used in training,validation and testing of SCNN-FC-8."}


par(mfrow=c(1,2),mai=c(0,.2,0,.2),bty="n")

  plot(region,col='red',xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
  plot(ons,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="",add=TRUE)
  plot(studyarea,col='grey',add=TRUE)
  plot(gsvdates,pch=16,cex=0.15,add=TRUE)
  scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
  #plot(studyarea,add=TRUE)
  par(usr=c(0,1,0,1))
  text(.1,.8,"a)",cex=1)
  #text(0.1,0.9,i,cex=2)



#win.graph(8.5,11)


  plot(region,col='red',xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
  plot(ons,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="",add=TRUE)
  plot(studyarea,col='gray',add=TRUE)
  plot(spd,pch=16,cex=0.15,add=TRUE)
  scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
  par(usr=c(0,1,0,1))  
  text(.1,.8,"b)",cex=1)
  # legend("bottomright",
  #      legend = c("GSV pano.","Study area","GSV access region"),pch=c(18,NA,NA),
  #      fill = c(NA,'grey','white'),
  #      border=c(NA,'black','black'),
  #      col='black',
  #      bty = "n", # turn off the legend border
  #      cex = .8) # decrease the font / legend size
  # #plot(studyarea,add=TRUE)
  # par(usr=c(0,1,0,1))
  #text(0.1,0.9,i,cex=2)
  legend("bottomright",
       legend = c("GSV pano.","Study area","GSV access region","Rural neighbourhoods"),pch=c(18,NA,NA,NA),
       fill = c(NA,'grey','red','white'),
       border=c(NA,'black','black','black'),
       col='black',
       bty = "o",
       bg="white",
       cex = .8) 

```

Next, we determine if the panoramas within the GSV access region can support analysis in the study area back to 2007.  The first GSV panoramas in the city were taken in 2007 and, naturally, we would like to map changes as far back as possible when describing the spatial evolution of gentrification in the study area. Thus, the possible temporal domain for this study is from 2007-2016 (we accessed imagery for this work in the spring of 2017).  However, GSV images may not be available at all time periods at all locations. In addition, we also also determine which years in the interval between 2007 and 2016 contained sufficient spatial coverage. 

Within the GSV access region (Figure S\ref{fig:allgsvdata}), the majority of properties had GSV images by 2012 (Figure S\ref{fig:histdates}a) and the majority of these were fully re-imaged between 2014-2016 (Figure S\ref{fig:histdates}b). 2012 is the year with the most panoramas (Figure S\ref{fig:histdates}c).  Figure S\ref{fig:histdates}c provide evidence of an approximate 2-3 year update frequency of GSV imagery. The average number of years that GSV panoramas are available at a property is `r round(mean(gsvdates$NYEARS),digits=2)` Figure S\ref{fig:histdates}d.   

```{r histdates, message=F, echo=FALSE, fig.width=5,fig.height=5,fig.cap="\\label{fig:histdates}a) Distribution of the oldest GSV date accessed at a location; b) Distribution of the Youngest GSV date accessed at a location; c) Distribution of all GSV image dates accessed at a location; d) Distribution of the number of years of GSV imagery at each queried location."}
par(mfrow=c(2,2),mai=c(.4,.65,.4,.1),bty="n")
hist(gsvdates$MINY,xlab="Date",ylim=c(0,80000),ylab="Number of GSV locations",main="")
par(usr=c(0,1,0,1),xpd=NA)
text(-.15,1.1,"a)",cex=1)
hist(gsvdates$MAXY,xlab="Date",ylab="",main="")
par(usr=c(0,1,0,1),xpd=NA)
text(-.15,1.1,"b)",cex=1)
av=read.delim("f:/models/allyearvector.csv",sep=",",header=F)
hist(av$V1,xlab="Date",ylab="Number of GSV locations",main="")
par(usr=c(0,1,0,1),xpd=NA)
text(-.15,1.1,"c)",cex=1)
hist(gsvdates$NYEARS,xlab="Number of years of imagery",ylab="",main="")
par(usr=c(0,1,0,1),xpd=NA)
text(-.15,1.1,"d)",cex=1)
```


```{r gsvdatesplot3, message=F,echo=FALSE,fig.width=4,fig.height=4,fig.cap="\\label{fig:gsvdatesplot3}Spatial distribution of properties that have a panorama in 2007 and also in 2015-2016."}
# Get GSV date list
x = read.delim("./rproject/ff_old_young2.csv",sep = ",",header = TRUE)

gsvdates_oldyoung = SpatialPointsDataFrame(cbind(x = x$LON, y = x$LAT), x)

# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates_oldyoung) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates_oldyoung = spTransform(gsvdates_oldyoung, srMTM9)

gsvdates_oldyoung=subset(gsvdates_oldyoung,MAXY>=2015)

#win.graph(8.5,11)
par(mai=c(.2,0,0,0),bty="n")

  plot(region,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
  plot(studyarea,col='gray',add=TRUE)
  plot(gsvdates_oldyoung,pch=16,cex=0.25,add=TRUE)
  scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
  #plot(studyarea,add=TRUE)
  par(usr=c(0,1,0,1))
  #text(0.1,0.9,i,cex=2)

legend("bottomright",
       legend = c("GSV pano.","Study area","GSV access region"),pch=c(18,NA,NA),
       fill = c(NA,'grey','white'),
       border=c(NA,'black','black'),
       col='black',
       bty = "n", # turn off the legend border
       cex = .8) # decrease the font / legend size

```

Examining all properties (locations) that contained an image in 2007 and one in the years 2015-2016 , most clearly defines the region in which we can make inferences back to 2007 (Figure S\ref{fig:gsvdatesplot3}).  We cannot, for example, make inferences regarding changes in the spatial distribution of gentrification-like visual changes between the years 2009-2010, since in 2010 there are almost no GSV panoramas.  


```{r alldatesplotovertime, message=FALSE, echo=FALSE,fig.width=6,fig.height=8.5,fig.cap="\\label{fig:alldatesplotovertime}Spatial distribution of all accessed GSV images through time."}
# Get GSV date list
q = read.delim("./rproject/allyearvector_coords.csv",sep = ",",header = FALSE)

gsvdatesAll = SpatialPointsDataFrame(cbind(x = q[,2], y = q[,1]), q)

# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdatesAll) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdatesAll = spTransform(gsvdatesAll, srMTM9)


#win.graph(8.5,11)
par(mfrow=c(5,2),mai=c(.2,0,0,0),bty="n")
for(i in seq(2007,2016,1)){
  y2007=subset(gsvdatesAll,V3==i)
  plot(region,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
  plot(studyarea,col='gray',add=TRUE)
  plot(y2007,pch=16,cex=0.25,add=TRUE)
  if (i==2007){  
    scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
    legend("bottomright",
       legend = c("GSV pano.","Study area","GSV access region"),pch=c(18,NA,NA),
       fill = c(NA,'grey','white'),
       border=c(NA,'black','black'),
       col='black',
       bty = "n", # turn off the legend border
       cex = .8) # decrease the font / legend size
    }
  #plot(studyarea,add=TRUE)
  par(usr=c(0,1,0,1))
  text(0.1,0.9,i,cex=2)
}


```

Concerning the spatial distribution of GSV images over the study period and within the study area, we examined the spatial distribution of the GSV panorama dates through time. In Figure S\ref{fig:gsvdatesplot3}, it is apparent that only the study region contains sufficient spatial coverage back to 2007 (Figure S\ref{fig:gsvdatesplot3}). Google did not expand coverage into the GSV access region until 2009 in Ottawa.  The study region is completely covered with panoramas in 2007,2009,2012,2014, and 2015 (Figure S\ref{fig:alldatesplotovertime}). Therefore, we were confident in using SCNN-FC-8 to detect gentrification-like visual changes within the study region.   Regarding the examination of gentrification through time, we can compare GSV panoramas within the study area between the years: 2007-2009,2009-2012,2012-2014 and between 2014 and a combined 2014-2016 (Figure S\ref{fig:gsvdatesplot3}).   

#Results
##SCNN-FC-8 model training and validation
```{python valcurves, echo=FALSE,eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:valcurves}Training and validation of SCNN-FC-8 (Epoch 1 to min(loss))."}
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'c:/programdata/Anaconda3/Library/plugins/platforms'
import numpy as np
def plot_loss(history_saved):
    import matplotlib.pyplot as plt
    mdict = np.load(history_saved)
    mdict = mdict.tolist()
    plt.figure(41, figsize=(12, 8), dpi=150)
    loss = mdict['loss']
    val_loss = mdict['val_loss']
    epochs = range(1, len(loss) + 1)
    plt.subplot(211)
    plt.plot(epochs, loss, 'b', label='Training loss', color='r')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.subplot(212)
    acc = mdict['binary_accuracy']
    val_acc = mdict['val_binary_accuracy']
    plt.plot(epochs, acc, 'b', label='Training acc', color='r')
    plt.plot(epochs, val_acc, 'b', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()
    
mdict = np.load("./rproject/mdict14try_vgg_norm.npy")
history_continue_training="./rproject/mdict14try_vgg_norm.npy"
mdict = mdict.tolist()
#print(max(mdict['val_binary_accuracy']))
plot_loss(history_continue_training)
```

##Building Permits
The City of Ottawa building permits are organized by month and by year in excel files and each permit contains fields such as address, date of issue and the description of work as well as the cost. We concatenated permit lists from July 2011 through December 2016 which produced a list of 56,269 permits that had 22631 unique descriptions. This total was reduced, as is explained in the following. 

Through permits’ descriptions it was possible to trim the list by removing those which were deemed redundant, as well as to establish a list of relevant permits (see Appendix XZ for details). After pruning the permit list, 1391 permit descriptions remained and were inspected manually, after which the total number of permits amounted to 27,509. 

After removing permits belonging to structures outside the study area, 6,342 permits remained.  Each remaining permit location was manually inspected on Street View, after which the list was further reduced to a final number of 2356. There were two criteria for retaining permits. The first was to only keep permits whose addresses can be seen on Street View, and the second was that the change observed to the property of the permit must have underwent a change which yielded a progressively more affluent structure. Some examples can include the addition of a car port, additions to the side of the house, or the construction of a completely new structure. However, more permits were removed (3986) than were kept. This is not to imply that the removed permit entrees are of structures which were not improved, but rather that their improvements are not visible from the street. Rear additions, basement alterations, and foundation repair are examples of improvements which do not necessarily yield a visual change. 

Street View lacks imagery on certain streets and segments of streets. This is most common with suburban subdivisions which are designated as privates. Some permits were deleted because their addresses were obfuscated on Street View. Other permits were deleted as the upgrades that they represented are not indicators of gentrification. This would include certain commercial infrastructure such as: industrial buildings, warehouses and storage structures. Institutional infrastructure was also removed, and included objects such as universities, schools, fire stations, churches, hospitals, community centers and transit infrastructure. 

The SQL statemetns used to refine the permits can be found here: https://github.com/laggiss/DeepMapping/blob/master/sql_statements_permits.txt

##SCNN-FC-8 and building permits
```{r aname, echo=FALSE,message=FALSE}


predpts.gt2011=subset(predpts,YEAR2>=2011)

permits@bbox=studyarea@bbox
predpts.gt2011@bbox=studyarea@bbox

# Calculate KDE on training locations & convert to raster obj
kdepredict=ptDensity(predpts.gt2011,studyarea,res=200)
kdepermits=ptDensity(permits,studyarea,res=200)

# Create class breaks
cint=densBreaks(kdepredict,9,'equal')

# Make color palette
my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)
```


```{r comparemodelpermit, message=FALSE,echo=FALSE,eval=TRUE, results='hide', fig.width=8,fig.height=4,fig.cap="\\label{fig:comparemodelpermit}Comparison between model predictions and building permits; a) Kernel density surface of SCNN-FC-8 predictions; b) KDE of building permits.  Both panels represent data from 2011 onwards.  See manuscript text for the explanation of the labelled locations (x is within Vanier North neighbourhood and x’ is within a neighbourhood named Glebe-Dow’s Lake)."}
plot.comparemodel=function(kde1,kde2,plotintervals,colorpal,nbrpoly){
  #set.panel()
  par(mfrow=c(1,2),mai=c(0,0,0,0),oma=c(0,0,0,4),bty="n")
  plot(kde1, breaks=plotintervals$brks,col = colorpal,axes=FALSE,legend=FALSE)
  plot(nbrpoly,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
  scalebar(d = 5000, 
           xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
  
  lines(c(370385.946, 375749.061),c(5033595.408,   5032711.698),lwd=1)  
  points(370385.946,  5033595.408,pch=16,col=1,cex=0.25)
  text(375749.061,5032711.698,"x",adj=c(-.5,.5))
  
  par(usr=c(0,1,0,1))
  text(0.05,0.8,"a)",cex=1)
  plot(kde2, breaks=plotintervals$brks,col = colorpal,axes=FALSE,legend=FALSE)
  plot(nbrpoly,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)


  lines(c(366410.724  , 368770.442 ),c(5035138.202 ,5029125.892),lwd=1)  
  points(368770.442,  5029125.892,pch=16,col=1,cex=0.25)
  text(366410.724,5035138.202,"x\'",adj=c(1,-0.5))

  par(usr=c(0,1,0,1))
  text(0.05,0.8,"b)",cex=1)
  
  # Add legend
  #set.panel(1,1)
  par(oma=c(0,0,0,1))
  tokmsq=1000^2
  r.range <- c(minValue(kde1), maxValue(kde1))*tokmsq
  plot(
    kde1,
    legend.only = TRUE,
    breaks = round(plotintervals$brks*tokmsq,digits=0),
    col = colorpal,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")(s[italic('x,y')] %.% km^-2)),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
    )
  )
}

#plot.comparemodel(kdepredict,kdepermits,cint,my.palette,nbrhoods)
```

We could have used KDE for point patterns based on a network *c.f.*[@okabe_spatial_2012]. However, strictly speaking, because the spatial support for the points relate to an area unit, the property, our point data violates the basic assumption of point pattern analyses, either in free space or on a network, both of which requires points to be representative of discrete entities. That being said, because the point locations (x,y) are a dimensional reduction of the property polygon, we use KDE on what is effectively a point process that contains dispersion at small scales - because the property areas are approximately equal. Our choice of bandwidth is much larger than the small scale dispersion among adjacent properties and so a valid way to visualize and compare patterns is by using KDE. We are interested in the location and scale of the gentrification process as defined by the clustering of gentrification-like visual changes.  

We found the pattern of building permits and SCNN-FC-8 predictions over the same period to be very similar, with only a few minor deviations (Figure 5 in Manuscript).

```{r, savedensfplot, echo=FALSE, eval=FALSE, message=FALSE,results='hide'}
# makeplot
png("./figures/figure_pred_vs_permit.png",units="in",width=11,height=4,res=300)
plot.comparemodel(kdepredict,kdepermits,cint,my.palette,nbrhoods)
dev.off()
```

```{r differencemap, echo=FALSE, message=FALSE, eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:differencemap}Proportional difference betweeen predicted KDE and permit KDE."}

par(bty="n")
par(mfrow=c(1,2),mai=c(0,.5,0,0),oma=c(0,0,0,4),bty="n")

kdepredict200=ptDensity(predpts.gt2011,studyarea,res=200)
kdepermits200=ptDensity(permits,studyarea,res=200)

kdepredict.n=(kdepredict200-0)/(cellStats(kdepredict200,stat='max')-0)
kdepermits.n=(kdepermits200-0)/(cellStats(kdepermits200,stat='max')-0)
kde.df=kdepredict.n-kdepermits.n

# Create class breaks
cint.d=densBreaks(kde.df,9,'equal')

# Make color palette
mypal=brewer.pal(10,"Spectral") #colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)

plot(kde.df, breaks=cint.d$brks,col = mypal,axes=FALSE,legend=FALSE)
plot(nbrhoods,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)

  lines(c(366410.724  , 368770.442 ),c(5035138.202 ,5029125.892),lwd=1)  
  points(368770.442,  5029125.892,pch=16,col=1,cex=0.25)
  text(366410.724,5035138.202,"x\'",adj=c(1,-0.5))
  lines(c(370385.946, 375749.061),c(5033595.408,   5032711.698),lwd=1)  
  points(370385.946,  5033595.408,pch=16,col=1,cex=0.25)
  text(375749.061,5032711.698,"x",adj=c(-.5,.5))
  scalebar(d = 5000, 
           xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
 # Add legend
  #set.panel(1,1)
  #par(oma=c(0,0,0,1))
  par(usr=c(0,1,0,1))
  text(0.05,0.8,"a)",cex=1)
  plot(
    kde.df,
    legend.only = TRUE,
    breaks = round(cint.d$brks,digits=3),
    col = mypal,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")[model-permit]),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
    )
  )
  
  # compute local correlation to examine.
rasterStack=stack(kdepermits.n,kdepredict.n)#crop(kdepredict.n,studyarea),crop(kdepermits.n,studyarea))
positionRaster <- raster(rasterStack, 1)
values(positionRaster) <- 1:ncell(rasterStack)

focal_cor <- focal(
  x = positionRaster,
  w = matrix(1, 5, 5),
  fun = function(x, y = rasterStack){
    cor(values(y)[x, 1], values(y)[x, 2],
        use = "na.or.complete")
  }
)

# compute local correlation to examine.
rasterStack=stack(kdepermits.n,kdepredict.n)#crop(kdepredict.n,studyarea),crop(kdepermits.n,studyarea))
positionRaster <- raster(rasterStack, 1)
values(positionRaster) <- 1:ncell(rasterStack)

focal_cor <- focal(
  x = positionRaster,
  w = matrix(1, 5, 5),
  fun = function(x, y = rasterStack){
    cor(values(y)[x, 1], values(y)[x, 2],
        use = "na.or.complete")
  }
)

#par(bty="n")


kde.df=focal_cor
kde.df <- crop(kde.df, extent(studyarea))
kde.df <- raster::mask(kde.df, studyarea)
# Create class breaks
cint.d=densBreaks(kde.df,9,'equal')

# Make color palette
mypal=brewer.pal(10,"PRGn") #colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)

plot(kde.df, breaks=cint.d$brks,col = mypal,axes=FALSE,legend=FALSE)
plot(nbrhoods,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)

  lines(c(366410.724  , 368770.442 ),c(5035138.202 ,5029125.892),lwd=1)  
  points(368770.442,  5029125.892,pch=16,col=1,cex=0.25)
  text(366410.724,5035138.202,"x\'",adj=c(1,-0.5))
  lines(c(370385.946, 375749.061),c(5033595.408,   5032711.698),lwd=1)  
  points(370385.946,  5033595.408,pch=16,col=1,cex=0.25)
  text(375749.061,5032711.698,"x",adj=c(-.5,.5))
  scalebar(d = 5000, 
           xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
 # Add legend
  #set.panel(1,1)
  #par(oma=c(0,0,0,1))
  par(usr=c(0,1,0,1))
  text(0.05,0.8,"b)",cex=1)
  plot(
    kde.df,
    legend.only = TRUE,
    breaks = round(cint.d$brks,digits=3),
    col = mypal,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = "Pearson's r",
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
    )
  )
  
```

Figure S\ref{fig:differencemap}a illustrates the difference between the standardized intensity {lambda} of the SCNN-FC-8 KDE prediction map and KDE of building permits. The two isolated regions of intensity in Figure S\ref{fig:differencemap}a, x and x', clearly stand out as the two largest differences between the model predictions and the building permits.   As discussed in the main text, x' is due to a large development of Landsdowne Park (https://en.wikipedia.org/wiki/Lansdowne_Park_redevelopment), and x was due to false positive detection's of gentrification-like visual change because of offset/FOV issues.  In particular, in the region denoted by x', there were a number of new homes constructed which normally would have been detected by SCNN-FC-8 within the image sequence.  However, after examining the sequences of GSV images in the region of x', a common theme became apparent in the sequence of visual changes: Initially, a park was present and that was followed by construction of a large wall. The wall was eventual removed and a new house was constructed.  The change from a wall to a residential structure, or from a park to wall for that matter, was not something that SCNN-FC-8 encountered in our training data set.  Thus such changes were not reinforced in training as being gentrification-like instances of visual change.

Figure S\ref{fig:differencemap}b represents the local Pearson's correlation coefficient between the standardized intensity {lambda} of the SCNN-FC-8 KDE prediction map and KDE of building permits. We use the correlation coefficient **r** as an exploratory tool to identify local regions of similarity/dissimilarity in intensity between the model predictions and the permits.  This map represents the correlation coefficient in a 5x5 moving window between the standardized values from Figure S\ref{fig:comparemodelpermit}a and b.  The large amount of green area in Figure S\ref{fig:differencemap}b, indicates that the majority of the intensity values strongly covary, which is evident in the visual inspection of Figure 5ab (Manuscript).  There are strong dissimilarities or negative correlations locally, but these are generally in areas of very low spatial intensity around the southern boundary of the study region. In other words, the majority of disagreements in the model/permits comparison are in regions where there are few gentrification-like visual changes.  This further reinforces the concordance seen between SCNN-FC-8 and the building permits upon visual comparison of their mapped intensities.


#SCNN-FC-8 sensitivity
```{r timeseries, echo=FALSE,eval=FALSE, message=FALSE,warning=FALSE, results='hide',fig.width=8,fig.height=6,fig.cap="\\label{fig:timeseries}Comparison of SCNN-FC-8 predictions over time (a) 2009 (b) 2012 (c) 2014 (d) 2015-16."}
#set.panel()
plot.time=function(){
  tokmsq=1000000
  plot.t=function(predpts,year){
    # Get predictions
    if(year==2015){
      predpts.gt2009=subset(predpts,(YEAR2==year)|(YEAR2==2016))
      #print(predpts.gt2009)
    }
    else{
      predpts.gt2009=subset(predpts,YEAR2==year)
    }
    predpts.gt2009=subset(predpts,YEAR2==year)
    predpts.gt2009@bbox=studyarea@bbox
    # Calculate KDE on training locations & convert to raster obj
    kde=ptDensity(predpts.gt2009,studyarea,res=200)
    return(kde*tokmsq)
  }
  
  
  
  par(mfrow=c(2,2),mai=c(0,0,0,.2),oma=c(0,0,0,1),bty="n")
  # Create class breaks
  blist=list()
  valvec=vector("numeric")
  
  for(i in c(2009,2012,2014,2015)){
   
    
      blist[[as.character(i)]]=plot.t(predpts,i)
    

    #blist[[i]]
    # tvals=values(blist[[i]])
    # valvec=c(valvec,tvals)
  }

  # Make color palette
  my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)
  lablist=list()
  lablist[['2009']]="a)"
  lablist[['2012']]="b)"
  lablist[['2014']]="c)"
  lablist[['2015']]="d)" 
  
  for(i in c('2009','2012','2014','2015')){
    #valvec=valvec[!is.na(valvec)]*tokmsq
    # if((i=='2012') | (i == '2015')){
    #   par(oma=c(0,0,0,1))
    # }
    # else{
    #   par(oma=c(0,0,0,4))
    #   
    # }
      
    cintx=densBreaks(blist[[i]],9,'equal')
    plot(blist[[i]], breaks=cintx$brks,col = my.palette,axes=FALSE,legend=FALSE)
    plot(nbrhoods,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
    if(i==2009) {
      #pl=polygonsLabel(labelhoods,labelhoods@data$names,method='inpolygon',cex=0.5,polypart = 'largest')
      #print(pl)
      scalebar(d = 5000, xy = c(357258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
      tlabs=readRDS("./rproject/figurelabs.rds")
      cntr=1
      for(o in tlabs){
        lines(o)
        text(o$x[2],o$y[2],labels(tlabs)[cntr],cex=0.5,pos=2,offset=.1)
        cntr=cntr+1
      }
      
    }
    par(usr=c(0,1,0,1))
    text(0.05,0.9,lablist[[i]],cex=1)
    #set.panel(1,1)
  #par(oma=c(0,0,0,1))
  plot(
    blist[[i]],
    legend.only = TRUE,
    add=TRUE,
    breaks = round(cintx$brks,digits=0),
    col = my.palette,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")(s[italic('x,y')] %.% km^-2)),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
      )
    )
  }
 
}

#plot.time()

```


```{r, savetimeplot, eval=FALSE, echo=FALSE,message=FALSE,results='hide'}
# makeplot
png("./figures/predovertime.png",units="in",width=8,height=6,res=300)
plot.time()
dev.off()
```


```{r run2, echo=FALSE, eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:run2}Comparison of SCNN-FC-8 predictions (a) using first run (b) using second run"}
spdrep@bbox=studyarea@bbox
spdo@bbox=studyarea@bbox
kderun1=ptDensity(spdo,studyarea,res=200)
kderun2=ptDensity(spdrep,studyarea,res=200)
cintn=densBreaks(kderun2,9,'equal')
plot.comparemodel(kderun1,kderun2,cintn,my.palette,nbrhoods)

```

```{r  echo=FALSE,eval=FALSE,message=FALSE,results='hide'}
png("./figures/figure_run1_vs_run2.png",units="in",width=11,height=4,res=300)
plot.comparemodel(kderun1,kderun2,cintn,my.palette,nbrhoods)
dev.off()


```

After training SCNN-FC-8 as described in the manuscript, we wanted a crude test of how different our results would be if we reshuffled all of the training data and re-trained the model from scratch (the model training procedure is described in the manuscript).  The training data set contained all 16224 GSV panoramas and we used 60% of these to train SCNN-FC-8, holding back 20% for model validation during training, and the last 20% were held back for testing the model once we achieved our desired model validation accuracy. All 16224 panorama pairs were shuffled/permuted prior to being split.  To retrain the model once again, we simply reshuffled all 16224 panorama pairs and reapplied the training procedure.   After training this second model instance, all GSV image sequences were fed through the model and the results were mapped (Figure S\ref{fig:run2}).  The spatial pattern of intensity between SCNN-FC-8 (Figure S\ref{fig:run2}a) and the second model (Figure S\ref{fig:run2}b) are nearly identical.  This suggests that the results obtained using SCNN-FC-8 are not significantly biased by the train/validation/test split.


#Activation maps
Activation maps can be used to explore which features in a GSV image are most strongly reinforced in SCNN-FC-8.  The activation maps of the last convolutional block for each image in a properties sequence (Figure S\ref{fig:saliency}), aid in revealing the potential reasons why some false-positive detections were made by SCNN-FC-8. Generally, we expect similar activation maps on the t[0] and t[0]+1 panoramas when no gentrification-like visual change is detected by SCNN-FC-8.  Conversely, when a change is detected, there should be differences in which features are most strongly activated upon by SCNN-FC-8.   The activation maps in Figure S\ref{fig:saliency} correspond to the images in the manuscript Figure 7.  See manuscript for further explanations.

```{r examples, eval=FALSE, message=FALSE,  echo=FALSE,message=FALSE,results='hide',fig.width=8,fig.height=11,fig.cap="\\label{fig:examples}Illustrative examples of SCNN-FC-8 predictions.  Each row represents the time series of GSV images for the unique location specified in the map plot at the end of each row. The delta symbol between any two years indicates where the SCNN-FC-8 predicted a visual change; (a to d) Normal cases of a single predicted change across the series of images at a given unique location. (e to k) represent cases where the model predicted more than one change or a false positive change wihtin the sequence.  See text for further details."}
library(imager)
#subtlechanges
  #F:\ottawa_image_db\45.395218,-75.751936
#6 commercial fov change plus occulusion
  #F:\ottawa_image_db\45.395869,-75.746973
#3 normal
  #F:\ottawa_image_db\45.385107,-75.742958
#5 normal next-door + occulusion
  #F:\ottawa_image_db\45.395435,-75.757202
#5 normal
  #F:\ottawa_image_db\45.395583,-75.757286
#6 occulusion tree
  #F:\ottawa_image_db\45.386234,-75.760761
#5 normal even with tree occulusion
  #F:\ottawa_image_db\45.385075,-75.763422
#5 normal subtle landscaping of front
  #F:\ottawa_image_db\45.387784,-75.759421
#6 landscaping front but for construction
  #F:\ottawa_image_db\45.386081,-75.751291
#6 wrong picture indicating normal
  #F:\ottawa_image_db\45.395496,-75.749797
#5 false positive due to occulusion by large tree and shadow
  #F:\ottawa_image_db\45.391192,-75.745004
#5 real plus occulusion
  #F:\ottawa_image_db\45.386595,-75.755356
#5 false positive occulusion
  #F:\ottawa_image_db\45.388473,-75.758767
#5 multiyear
  #F:\ottawa_image_db\45.342973,-75.785467
#5 normal
  #F:\ottawa_image_db\45.351836,-75.742754
#5 normal
  #F:\ottawa_image_db\45.353614,-75.742434
#5 normal
  #F:\ottawa_image_db\45.353038,-75.743813
#5 normal
  #F:\ottawa_image_db\45.352735,-75.746411
#5 normal
  #F:\ottawa_image_db\45.348013,-75.743336
#5 normal
  #F:\ottawa_image_db\45.353763,-75.747868

plotexamples=function(){
dlist=c("F:/ottawa_image_db/45.395289,-75.734107",
        "F:/ottawa_image_db/45.353038,-75.743813",
        "F:/ottawa_image_db/45.430856,-75.634009",
        "F:/ottawa_image_db/45.387784,-75.759421",
        "F:/ottawa_image_db/45.331311,-75.790179",
        "F:/ottawa_image_db/45.368548,-75.779295",
        "F:/ottawa_image_db/45.391854,-75.759665",
        "F:/ottawa_image_db/45.440927,-75.671258",
        "F:/ottawa_image_db/45.405719,-75.726039",
        "F:/ottawa_image_db/45.439506,-75.661335",
        "F:/ottawa_image_db/45.381848,-75.760526")#,
        #         "F:/ottawa_image_db/45.362226,-75.784759"       "F:/ottawa_image_db/45.391192,-75.745004","F:/ottawa_image_db/45.348997,-75.712858","F:/ottawa_image_db/45.348013,-75.743336","F:/ottawa_image_db/45.399765,-75.756267",
        #"F:/ottawa_image_db/45.398931,-75.756158")
# dlist=c("F:/ottawa_image_db/45.405719,-75.726039")
# dlist=c("F:/ottawa_image_db/45.369725,-75.628113")
# dlist=c("F:/ottawa_image_db/45.362226,-75.784759")
#F:\ottawa_image_db\45.368548,-75.779295,F:\ottawa_image_db\45.367637,-75.778784,F:\ottawa_image_db\45.397599,-75.754770,F:\ottawa_image_db\45.397651,-75.754588 F:/ottawa_image_db/45.385800,-75.746943
par(mfrow = c(11, 6), mai = c(0, .2, .2, 0))
crow=1

for(k in dlist) {
  curd = strsplit(dlist[crow], "/")[[1]][3]
  ss = subset(predptso, DIRNAME == curd)
  
  
  lf = list.files(dlist[crow],
  full.names = F,
  pattern = "\\.jpg$")
  
  tst = vector("character")
  for (i in lf) {
    tst = c(tst, strsplit(i, "_")[[1]][1])
  }
  
  # tst = data.frame(allyears = tst)
  # ssdf = data.frame(allyears = c(ss@data$YEAR1[1], ss@data$YEAR2))
  allyears = as.character(ss@data$YEAR2)
  par(mfg=c(crow,1))
  pcount=1
  for (i in lf) {
    j1 = load.image(paste(dlist[crow], "/", i, sep = ""))
    plot(j1, axes = F)
    if (pcount == 1){
      par(las=1)
      mtext(paste(letters[crow], ")"), 2, crt = 90)#mtext("(a)",3)
      par(las=0)
    }
    tt = strsplit(i, "_")[[1]][1]
    mtext(tt, 3)
    if (tt %in% allyears) {
      par(las=1)
      mtext("<|>", 2,cex=2)#expression(bold(Delta))"\u26AB"
      par(las=0)
    }
    pcount = pcount + 1
  }
  plot(studyarea)
  xy=strsplit(strsplit(k,'/')[[1]][3],",")
  xy=SpatialPoints(cbind(x=as.numeric(xy[[1]][2]),y=as.numeric(xy[[1]][1])),proj4string=srNAD83)
  xy=spTransform(xy,srMTM9)
  plot(xy,pch=16,col=2,add=TRUE)
  crow=crow+1
}
}
plotexamples()
```



```{r  echo=FALSE,eval=FALSE,message=FALSE,results='hide'}
png("./figures/examples.png",units="in",width=6.5,height=10,res=300)
plotexamples()
dev.off()


```

```{r saliency, eval=TRUE,echo=FALSE,message=FALSE,results='hide',  fig.width=7,fig.height=9.5,fig.cap="\\label{fig:saliency}Class activation heat maps of \\label{fig:examples} based on the last convolutional layer in SCNN-FC-8."}
library(imager)

plotexamples2=function(){
dlist=c("F:/ottawa_image_db/45.395289,-75.734107",
        "F:/ottawa_image_db/45.353038,-75.743813",
        "F:/ottawa_image_db/45.430856,-75.634009",
        "F:/ottawa_image_db/45.387784,-75.759421",
        "F:/ottawa_image_db/45.331311,-75.790179",
        "F:/ottawa_image_db/45.368548,-75.779295",
        "F:/ottawa_image_db/45.391854,-75.759665",
        "F:/ottawa_image_db/45.440927,-75.671258",
        "F:/ottawa_image_db/45.405719,-75.726039",
        "F:/ottawa_image_db/45.439506,-75.661335",
        "F:/ottawa_image_db/45.381848,-75.760526")#,

par(mfrow = c(11, 6), mai = c(0, .2, .2, 0))
crow=1

for(k in dlist) {
  curd = strsplit(dlist[crow], "/")[[1]][3]
  ss = subset(predptso, DIRNAME == curd)
  
  
  lf = list.files(dlist[crow],
  full.names = F,
  pattern = "\\.jpg$")
  
  # tst = vector("character")
  # for (i in lf) {
  #   tst = c(tst, strsplit(i, "_")[[1]][1])
  # }
  # 
  # # tst = data.frame(allyears = tst)
  # # ssdf = data.frame(allyears = c(ss@data$YEAR1[1], ss@data$YEAR2))
  allyears = as.character(ss@data$YEAR2)
  par(mfg=c(crow,1))
  pcount=1
  for (i in lf) {
    j1 = load.image(paste("f:/fakedir", "/score", i, sep = ""))
    plot(j1, axes = F)
    if (pcount == 1){
      par(las=1)
      mtext(paste(letters[crow], ")"), 2, crt = 90)#mtext("(a)",3)
      par(las=0)
    }
    tt = strsplit(i, "_")[[1]][1]
    mtext(tt, 3)
    if (tt %in% allyears) {
      par(las=1)
      mtext("|", 2,cex=2)#expression(bold(Delta))"\u26AB"
      par(las=0)
    }
    pcount = pcount + 1
  }
  plot(studyarea)
  xy=strsplit(strsplit(k,'/')[[1]][3],",")
  xy=SpatialPoints(cbind(x=as.numeric(xy[[1]][2]),y=as.numeric(xy[[1]][1])),proj4string=srNAD83)
  xy=spTransform(xy,srMTM9)
  plot(xy,pch=16,col=2,add=TRUE)
  crow=crow+1
}
}
plotexamples2()
```


```{r  echo=FALSE,eval=FALSE,message=FALSE,results='hide'}
png("./figures/examples_sal.png",units="in",width=6.5,height=10,res=300)
plotexamples2()
dev.off()


```

# References













