---
output:
  pdf_document:
    fig_caption: yes
  html_document:
    df_print: paged
    fig_caption: yes
  word_document: 
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
use_python("c:/programdata/anaconda3/python.exe")
```

#Import required libraries
```{r message=FALSE}
library(spatstat)
library(maptools)
library(stringr)
library(raster)
library(dplyr)
library(classInt)
library(rgdal)
library(fields)
```

###Functions
```{r functions}
ptDensity = function(a, sarea) {
  # Calculate KDE
  kdepredict = density.ppp(as.ppp(a),
  eps = 200,
  kernel = 'gaussian',
  sigma = 200)
  kdepredict = raster(kdepredict)
  kdepredict <- crop(kdepredict, extent(sarea))
  kdepredict <- mask(kdepredict, sarea)
  return(kdepredict)
}


densBreaks = function(kdepredict,n,style) {
  if(!(is.numeric(kdepredict)=="numeric")) {
    vals = values(kdepredict)
  vals = vals[!is.na(vals)]
  }
  else{vals=kdepredict}
  cint = classIntervals(vals, n = n, style = style)
  return(cint)
}

openSPDF = function(shapefilepath,outCS=CRS("+init=epsg:32189")) {
  permitpts.b=readOGR(shapefilepath)#,stringsAsFactors = FALSE)
  # arc.check_product()
  # permitpts = arc.open(shapefilepath)
  # permitpts.a = arc.select(permitpts)
  # permitpts.b = arc.data2sp(permitpts.a)
  permits = spTransform(permitpts.b, outCS)
  return(permits)
}
```

#Training data distribution
Open training data file "retrain.txt", get coordinates, create spdf, project to mtm9.  Also open studyarea polygons.
```{r trainingdata, message=FALSE}
# Get training data list
x = read.delim("./rproject/retrain.txt",sep = " ",header = FALSE)

ll = lapply(str_split(x[, 1], "/"), function(x)
  x[4])
yy = unlist(lapply(str_split(ll, ","), function(x)
  x[1]))
xx = unlist(lapply(str_split(ll, ","), function(x)
  x[2]))

yy = unlist(lapply(str_split(yy, "new-"), function(x) {
  if (length(x) == 2) {
    x[2]
  }
  else{
    x[1]
  }
}))

# Check for NA
yy[is.na(as.numeric(yy))]


xx = unlist(lapply(str_split(xx, "new-"), function(x) {
  if (length(x) == 2) {
    x[2]
  }
  else{
    x[1]
  }
}))

# Check for NA
xx[is.na(as.numeric(xx))]


# put x,y into x dataframe for coordinates of each pair

x$Long = xx
x$Lat = yy
x = x[which(x$V3 != "np"),]
x = x[which(x$V3 != "nof"),]

# Remove nonused levels of factors (3 or 4 bad rows)
x = droplevels(x)

#
# Make spdf of training data duels file

spd = SpatialPointsDataFrame(cbind(x = as.numeric(x$Long), y = as.numeric(x$Lat)), x)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spd) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spd = spTransform(spd, srMTM9)

# Read in the replicated model run
x1=read.csv("./rproject/fullres_replicate.csv")
x1=x1[x1$PRED==1,]

spdrep = SpatialPointsDataFrame(cbind(x = as.numeric(x1$LONG), y = as.numeric(x1$LAT)), x1)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spdrep) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spdrep = spTransform(spdrep, srMTM9)

# Read in the original model run

xo=read.csv("./rproject/fullres.csv")
xo=xo[xo$PRED==1,]

spdo = SpatialPointsDataFrame(cbind(x = as.numeric(xo$LONG), y = as.numeric(xo$LAT)), xo)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spdo) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spdo = spTransform(spdo, srMTM9)



# Make unique point file for probabilities
#spdU=remove.duplicates(spd)

# Open study area mask, convert to spdf and reproject to MTM9
m4 = openSPDF(shapefilepath = './shapefiles/core_multi.shp')

permits=openSPDF(shapefilepath = './shapefiles/permits.shp')

options(stringsAsFactors = FALSE)
predpts=openSPDF(shapefilepath = './shapefiles/predicted.shp')
predpts@data$YEAR1=as.numeric(predpts@data$YEAR1)
predpts@data$YEAR2=as.numeric(predpts@data$YEAR2)
predpts@data$PRED=as.numeric(predpts@data$PRED)
options(stringsAsFactors = TRUE)

studyarea=openSPDF(shapefilepath = './shapefiles/core_multi.shp')

nbrhoods=openSPDF(shapefilepath = './shapefiles/core.shp')

outercore=openSPDF(shapefilepath = './shapefiles/outercore.shp')

```

Create KDE estimates of training data distrbution
```{r traindistribution}
kde.training = ptDensity(spd,outercore)
spd.yes=subset(spd,V3==1)
spd.no=subset(spd,V3==0)
kde.training.yes = ptDensity(spd.yes,outercore)
kde.training.no = ptDensity(spd.no,outercore)

# Create class breaks
cint=densBreaks(kde.training,9,'kmeans')
cint2=densBreaks(kde.training.yes,9,'kmeans')
cint3=densBreaks(kde.training.no,9,'kmeans')
# Make color palette
my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(9)
```

```{r kdetrain, fig.width=8,fig.height=4,fig.cap="\\label{fig:kdetrain}a)Distribution of all GSV training images; b) only training pairs that are positive for change; c) only pairs that are negative for change."}
# makeplot
#windows(width=8,height=11,xpinch=300,ypinch=300)
par(mfrow=c(3,1),mai=c(0,0,0,0),bty="n")
p.plot=function(tras,cbreaks,outercore,letter){
  plot(tras, breaks=cbreaks$brks,col = my.palette,axes=FALSE,legend=FALSE)
  plot(outercore,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
  par(usr=c(0,1,0,1))
  text(0.1,0.9,letter,cex=2)
}
p.plot(kde.training,cint,outercore,"A")
p.plot(kde.training.yes,cint2,outercore,"B")
p.plot(kde.training.no,cint3,outercore,"C")
```

The pattern of building permits and SCNN-FC-8 predictions are very similar in Figure \ref{fig:kdetrain}.

```{r kdetrain_fig, eval=TRUE,echo=FALSE,message=FALSE}
# makeplot
png("./figures/KDE_TRAINING_DISTRIB.png",units="in",width=7,height=12,res=300)
par(mfrow=c(3,1),mai=c(0.1,0,0.1,0),bty="n")

p.plot(kde.training,cint,outercore,"A")
p.plot(kde.training.yes,cint2,outercore,"B")
p.plot(kde.training.no,cint3,outercore,"C")

dev.off()
```

Get oldest date for GSV imagery, youngest date and span
```{python py, eval=FALSE}
import glob
import os
basedir='f:/ottawa_image_db/'
dirlist = os.listdir(basedir)

with open(r"F:\OneDrive\DeepMapping\rproject\gsvdatesspan.csv", "w") as f:
    for d in dirlist:
        images = glob.glob(basedir+d+ '/*.jpg')
        if len(images)!=0:
            dlist=[]
            for image in images:
                fn=os.path.basename(image)
                dlist.append(fn[0:4])
            mx=max(dlist)
            mn=min(dlist)
            diff=int(mx)-int(mn)
            f.write("{},{},{},{}\n".format(d, mn,mx,diff))
            print(dlist,min(dlist))
```

#GSV panorama locations
Load GSV dates, create SPDF, assign and project.
```{r gsvdates, fig.width=7,fig.height=9.5,fig.cap="\\label{fig:gsvdates}Spatial distribution of the oldest date found at each location where GSV images were accessed."}
# Get GSV date list
x = read.delim("./rproject/GSVDATESSPAN.csv",sep = ",",header = FALSE)
names(x)=c("LAT","LONG","OLDEST","YOUNGEST","SPAN")
# Make spdf of training data duels file

gsvdates = SpatialPointsDataFrame(cbind(x = x$LONG, y = x$LAT), x)

# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates = spTransform(gsvdates, srMTM9)

#win.graph(8.5,11)
par(mfrow=c(5,2),mai=c(0,0,0,0),bty="n")
for(i in seq(2007,2016,1)){
  y2007=subset(gsvdates,OLDEST==i)
  plot(studyarea)
  plot(y2007,pch=16,cex=0.5,add=TRUE)
  #plot(studyarea,add=TRUE)
  par(usr=c(0,1,0,1))
  text(0.1,0.9,i,cex=2)
}



```
Examine date distribution
```{r histdates, fig.width=7,fig.height=6,fig.cap="\\label{fig:histdates}Distribution of the oldest GSV date accessed at a location"}
hist(gsvdates$OLDEST,xlab="Date",ylab="Number of GSV locations",main="")
```

Both Figure \ref{fig:histdates} and \ref{fig:gsvdates} provide evidence of an approximate 2-3 year update frequency of GSV imagery. Both distributions also indicate that over the 10-year period there has been a decreasing overall investement in the total number of images captured at each location. That decreasing trend is suggestive of perhaps an evolving collection strategy that is informed by satellite imagery, different goals for the product or less investment in the resources Google assigns to established collections of GSV imagery.  Moreover, in order to predict back to 2007 using SCNN-FC-8, Figure \ref{fig:gsvdates} shows that only the region of our current study area contains GSV imagery in 2007.

#Results
##Model Training curves
```{python valcurves, eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:valcurves}Training and validation of SCNN-FC-8."}
import numpy as np
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'c:/programdata/Anaconda3/Library/plugins/platforms'
def plot_loss(history_saved):
    import matplotlib.pyplot as plt
    mdict = np.load(history_saved)
    mdict = mdict.tolist()
    plt.figure(41, figsize=(12, 8), dpi=150)
    loss = mdict['loss']
    val_loss = mdict['val_loss']
    epochs = range(1, len(loss) + 1)
    plt.subplot(211)
    plt.plot(epochs, loss, 'b', label='Training loss', color='r')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.subplot(212)
    acc = mdict['binary_accuracy']
    val_acc = mdict['val_binary_accuracy']
    plt.plot(epochs, acc, 'b', label='Training acc', color='r')
    plt.plot(epochs, val_acc, 'b', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()
    
mdict = np.load("f:/deepmappingdata/mdict14try_vgg_norm.npy")
history_continue_training="f:/deepmappingdata/mdict14try_vgg_norm.npy"
mdict = mdict.tolist()
max(mdict['val_binary_accuracy'])
plot_loss(history_continue_training)
```



##Comparison between SCNN-FC-8 predictions and building permits
```{r aname}
# Get predictions after 2011
predpts.gt2011=subset(predpts,YEAR2>=2011)

permits@bbox=studyarea@bbox
predpts.gt2011@bbox=studyarea@bbox

# Calculate KDE on training locations & convert to raster obj
kdepredict=ptDensity(predpts.gt2011,studyarea)
kdepermits=ptDensity(permits,studyarea)

# Create class breaks
cint=densBreaks(kdepredict,9,'equal')

# Make color palette
my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)
```
Plot comparison between permits and model results.

```{r comparemodelpermit, eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:comparemodelpermit}Comparison of SCNN-FC-8 predictions (a) with building permits (b)."}
plot.comparemodel=function(kde1,kde2,plotintervals,colorpal,nbrpoly){
  set.panel()
  par(mfrow=c(1,2),mai=c(0,0,0,0),oma=c(0,0,0,4),bty="n")
  plot(kde1, breaks=plotintervals$brks,col = colorpal,axes=FALSE,legend=FALSE)
  plot(nbrpoly,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
  scalebar(d = 5000, 
           xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
  par(usr=c(0,1,0,1))
  text(0.05,0.9,"A",cex=2)
  plot(kde2, breaks=plotintervals$brks,col = colorpal,axes=FALSE,legend=FALSE)
  plot(nbrpoly,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
  
  par(usr=c(0,1,0,1))
  text(0.05,0.9,"B",cex=2)
  
  # Add legend
  set.panel(1,1)
  par(oma=c(0,0,0,1))
  tokmsq=1000^2
  r.range <- c(minValue(kde1), maxValue(kde1))*tokmsq
  plot(
    kde1,
    legend.only = TRUE,
    breaks = round(plotintervals$brks*tokmsq,digits=0),
    col = colorpal,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")(s[italic('x,y')] %.% km^-2)),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
    )
  )
}

plot.comparemodel(kdepredict,kdepermits,cint,my.palette,nbrhoods)
```

The pattern of building permits and SCNN-FC-8 predictions are very similar in Figure \ref{fig:comparemodelpermit}.

```{r, savedensfplot, eval=FALSE, echo=FALSE,message=FALSE}
# makeplot
png("./figures/figure_pred_vs_permit.png",units="in",width=11,height=4,res=300)
plot.comparemodel(kdepredict,kdepermits,cint,my.palette,nbrhoods)
dev.off()
```

#SCNN-FC-8 predictions over time
```{r timeseries, eval=TRUE, fig.width=6,fig.height=9,fig.cap="\\label{fig:timeseries}Comparison of SCNN-FC-8 predictions over time (a) 2009 (b) 2012 (c) 2013-2016."}
  set.panel()
plot.time=function(){
  tokmsq=1000000
  plot.t=function(predpts,year){
    # Get predictions
    predpts.gt2009=subset(predpts,YEAR2==year)
    predpts.gt2009@bbox=studyarea@bbox
    # Calculate KDE on training locations & convert to raster obj
    kde=ptDensity(predpts.gt2009,studyarea)
    return(kde*tokmsq)
  }
  
  par(mfrow=c(3,1),mai=c(0,0,0,.2),oma=c(0,0,0,4),bty="n")
  # Create class breaks
  blist=list()
  valvec=vector("numeric")
  
  for(i in c(2009,2012,2016)){
    blist[[as.character(i)]]=plot.t(predpts,i)
    #blist[[i]]
    # tvals=values(blist[[i]])
    # valvec=c(valvec,tvals)
  }

  # Make color palette
  my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)
  lablist=list()
  lablist[['2009']]="A"
  lablist[['2012']]="B"
  lablist[['2016']]="C"
  
  for(i in c('2009','2012','2016')){
    #valvec=valvec[!is.na(valvec)]*tokmsq
    #par(oma=c(0,0,0,4))
    cintx=densBreaks(blist[[i]],9,'equal')
    plot(blist[[i]], breaks=cintx$brks,col = my.palette,axes=FALSE,legend=FALSE)
    plot(nbrhoods,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
    if(i==2009) scalebar(d = 5000, xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
    par(usr=c(0,1,0,1))
    text(0.05,0.9,lablist[[i]],cex=2)
    #set.panel(1,1)
  #par(oma=c(0,0,0,1))
  plot(
    blist[[i]],
    legend.only = TRUE,
    add=TRUE,
    breaks = round(cintx$brks,digits=0),
    col = my.palette,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")(s[italic('x,y')] %.% km^-2)),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
      )
    )
  }
  # Add legend
 
}

plot.time()

```


```{r, savetimeplot, eval=TRUE, echo=FALSE,message=FALSE}
# makeplot
png("./figures/predovertime.png",units="in",width=6,height=9,res=300)
plot.time()
dev.off()
```




```{r excludetrain, eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:excludetrain}Comparison of SCNN-FC-8 predictions (a) using all training data (b) using only training data outside of 5 neighbourhoods"}
predex=read.csv("./rproject/fullres_replicate_onesonly_6f.csv")
predexspd = SpatialPointsDataFrame(cbind(x = as.numeric(predex$LONG), y = as.numeric(predex$LAT)), predex)

# Assign NAD83
cr = CRS("+init=epsg:4269")
proj4string(predexspd) = cr

# Reproject to MTM9 NAD83
cr = CRS("+init=epsg:32189")
predexspd = spTransform(predexspd, cr)
predexspd@bbox=studyarea@bbox
predexkde=ptDensity(predexspd,studyarea)
cint=densBreaks(predexkde,9,'equal')
plot.comparemodel(kdepredict,predexkde,cint,my.palette,nbrhoods)

```


```{r run2, eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:run2}Comparison of SCNN-FC-8 predictions (a) using first run (b) using second run"}
spdrep@bbox=studyarea@bbox
spdo@bbox=studyarea@bbox
kderun1=ptDensity(spdo,studyarea)
kderun2=ptDensity(spdrep,studyarea)
cintn=densBreaks(kderun2,9,'equal')
plot.comparemodel(kderun1,kderun2,cintn,my.palette,nbrhoods)

```

```{r}
png("./figures/figure_run1_vs_run2.png",units="in",width=11,height=4,res=300)
plot.comparemodel(kderun1,kderun2,cintn,my.palette,nbrhoods)
dev.off()


```
```{r}
spd2o=spdo
spd2o$X=coordinates(spd2o)[,1]
spd2o$Y=coordinates(spd2o)[,2]
```

```{python}
import pandas as pd
p=r.spd2o@Data

```


#Other stuff
```{r thinset, echo=FALSE,eval=FALSE}
# Calculate KDE on training locations & convert to raster obj
kde = ptDensity(spd,studyarea)

kde = raster(kde)

# Extract probabilities from KDE surface
probs = extract(kde, spd)

# Add the raster probabilities to spdf after standardizing and inverting
probs[is.na(probs)]=0
maxv = max(probs, na.rm = TRUE)
minv = min(probs, na.rm = TRUE)
probs=1 - (probs - minv) / (maxv - minv)
spd@data$RASTERVALU=probs


#
# Crop and mask raster to study area
r2 <- crop(kde, extent(m4))
r3 <- mask(r2, m4)

# Plot raster
plot(r3)
plot(m3, add = TRUE, lwd = 2)

# Create a thinned dataset
idx=1:length(spd@data$RASTERVALU)
ytest=sample(idx,600, replace = FALSE, prob = spd@data$RASTERVALU/sum(spd@data$RASTERVALU))
plot(spd@data$Long,spd@data$Lat,pch=16)
x=spd@data$Long[ytest]
y=spd@data$Lat[ytest]
points(x,y,col=2)

pts=spd[ytest,]
kde=density.ppp(as.ppp(pts),eps = 50,
                  kernel = 'quartic',
                  sigma = 750)
kde=raster(kde)
r2 <- crop(kde, extent(m4))
r3 <- mask(r2, m4)
plot(r3)
plot(spd[ytest,],add=TRUE,col=2,pch=16)


library(classInt)
vals=values(r3)
vals=vals[!is.na(vals)]
cint = classIntervals(vals,n=9,style='equal')

library(RColorBrewer)
my.palette <- brewer.pal(n = 9, name = "OrRd")
plot(r3, breaks=cint$brks,col = my.palette)


```
```{r data, echo=FALSE,eval=FALSE}
library(arcgisbinding)
arc.check_product()
da=arc.open('C:/Users/laggi/Documents/ArcGIS/Default.gdb/Extract_trainin1')

da2=arc.select(da)
da3=arc.data2sp(da2)

vals=da3@data$RASTERVALU
maxv=max(vals)
minv=min(vals)

da3@data$RASTERVALU=1-(da3@data$RASTERVALU-minv)/(maxv-minv)
library(dplyr)

stest=sample_n(da3@data, 100, replace = FALSE, weight = da3@data$RASTERVALU)
plot(da3@data$Long,da3@data$Lat,pch=16)
points(stest$Long,stest$Lat,col=2)

idx=1:length(da3@data$RASTERVALU)
ytest=sample(idx,600, replace = FALSE, prob = da3@data$RASTERVALU/sum(da3@data$RASTERVALU))
plot(da3@data$Long,da3@data$Lat,pch=16)
x=da3@data$Long[ytest]
y=da3@data$Lat[ytest]
points(x,y,col=2)

pts=da3[ytest,]
plot(density.ppp(as.ppp(pts),kernel='quartic',sigma=750))

# No density
idx=1:length(da3@data$RASTERVALU)
ytest=sample(idx,500, replace = FALSE)#, prob = da3@data$RASTERVALU)
plot(da3@data$Long,da3@data$Lat,pch=16)
x=da3@data$Long[ytest]
y=da3@data$Lat[ytest]
points(x,y,col=2)

#### Density
library(raster)

tloc=arc.open('C:/Users/laggi/Documents/ArcGIS/Default.gdb/Extract_trainin2')

tloc2=arc.select(tloc)
tloc3=arc.data2sp(tloc2)
vals=tloc3@data$RASTERVALU
maxv=max(vals,na.rm=TRUE)
minv=min(vals,na.rm=TRUE)

tloc3@data$RASTERVALU=1-(tloc3@data$RASTERVALU-minv)/(maxv-minv)
r=density.ppp(as.ppp(tloc3),eps=100,kernel='quartic',sigma=750)
r=raster(r)
#,weights=tloc3@data$RASTERVALU))
m=arc.open('C:/GIST/core_multi.shp')

m2=arc.select(m)
m3=arc.data2sp(m2)
m4=spTransform(m3, CRS(proj4string(tloc3)))

r2 <- crop(r, extent(m4))
r3 <- mask(r2, m4)

plot(r3)
plot(m3, add=TRUE, lwd=2)
```


















