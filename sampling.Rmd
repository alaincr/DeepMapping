---
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
  html_document:
    df_print: paged
    fig_caption: yes
  word_document: 
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
use_python("c:/programdata/anaconda3/python.exe")
```

NOTE: this docuemnt was created in RMarkdown and contains all of the R-code used to create maps and graphs although the R code is suppressed in this document. You can find the RMarkdown document with R-code at (https://github.com/laggiss/DeepMapping/blob/master/sampling.Rmd).

```{r message=FALSE, echo=FALSE}
#Import required libraries
library(spatstat)
library(maptools)
library(stringr)
library(raster)
library(dplyr)
library(classInt)
library(rgdal)
library(fields)
library(Hmisc)
library(RColorBrewer)
library(rgeos)
```


```{r functions, echo=FALSE}
###Functions
ptDensity = function(a, sarea) {
  # Calculate KDE
  kdepredict = density.ppp(as.ppp(a),
  eps = 200,
  kernel = 'gaussian',
  sigma = 200)
  kdepredict = raster(kdepredict)
  kdepredict <- crop(kdepredict, extent(sarea))
  kdepredict <- raster::mask(kdepredict, sarea)
  return(kdepredict)
}


densBreaks = function(kdepredict,n,style) {
  if(!(is.numeric(kdepredict)=="numeric")) {
    vals = values(kdepredict)
  vals = vals[!is.na(vals)]
  }
  else{vals=kdepredict}
  cint = classIntervals(vals, n = n, style = style)
  return(cint)
}

openSPDF = function(shapefilepath,outCS=CRS("+init=epsg:32189")) {
  permitpts.b=readOGR(shapefilepath,verbose=FALSE)#,stringsAsFactors = FALSE)
  # arc.check_product()
  permits = spTransform(permitpts.b, outCS)
  return(permits)
}
```

#Training data distribution

```{r trainingdata, echo=FALSE,message=FALSE}
#Open training data file "retrain.txt", get coordinates, create spdf, project to mtm9.  Also open studyarea polygons.
# Get training data list
x = read.delim("./rproject/retrain.txt",sep = " ",header = FALSE)

ll = lapply(str_split(x[, 1], "/"), function(x)
  x[4])
yy = unlist(lapply(str_split(ll, ","), function(x)
  x[1]))
xx = unlist(lapply(str_split(ll, ","), function(x)
  x[2]))

yy = unlist(lapply(str_split(yy, "new-"), function(x) {
  if (length(x) == 2) {
    x[2]
  }
  else{
    x[1]
  }
}))

# Check for NA
yy[is.na(as.numeric(yy))]


xx = unlist(lapply(str_split(xx, "new-"), function(x) {
  if (length(x) == 2) {
    x[2]
  }
  else{
    x[1]
  }
}))

# Check for NA
xx[is.na(as.numeric(xx))]


# put x,y into x dataframe for coordinates of each pair

x$Long = xx
x$Lat = yy
x = x[which(x$V3 != "np"),]
x = x[which(x$V3 != "nof"),]

# Remove nonused levels of factors (3 or 4 bad rows)
x = droplevels(x)

#
# Make spdf of training data duels file

spd = SpatialPointsDataFrame(cbind(x = as.numeric(x$Long), y = as.numeric(x$Lat)), x)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spd) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spd = spTransform(spd, srMTM9)

# Read in the replicated model run
x1=read.csv("./rproject/fullres_replicate.csv")
x1=x1[x1$PRED==1,]

spdrep = SpatialPointsDataFrame(cbind(x = as.numeric(x1$LONG), y = as.numeric(x1$LAT)), x1)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spdrep) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spdrep = spTransform(spdrep, srMTM9)

# Read in the original model run

xo=read.csv("./rproject/fullres.csv")
xo=xo[xo$PRED==1,]

spdo = SpatialPointsDataFrame(cbind(x = as.numeric(xo$LONG), y = as.numeric(xo$LAT)), xo)

# Assign NAD83
srNAD83= CRS("+init=epsg:4269")
proj4string(spdo) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
spdo = spTransform(spdo, srMTM9)



# Make unique point file for probabilities
#spdU=remove.duplicates(spd)

# Open study area mask, convert to spdf and reproject to MTM9
m4 = openSPDF(shapefilepath = './shapefiles/core_multi.shp')

permits=openSPDF(shapefilepath = './shapefiles/permits.shp')

options(stringsAsFactors = FALSE)
predpts=openSPDF(shapefilepath = './shapefiles/predicted.shp')
predpts@data$YEAR1=as.numeric(predpts@data$YEAR1)
predpts@data$YEAR2=as.numeric(predpts@data$YEAR2)
predpts@data$PRED=as.numeric(predpts@data$PRED)
options(stringsAsFactors = TRUE)

predptso=predpts
# Get predictions after 2011
predpts=remove.duplicates(predpts,remove.second = F)

studyarea=openSPDF(shapefilepath = './shapefiles/core_multi.shp')

nbrhoods=openSPDF(shapefilepath = './shapefiles/core.shp')

ons=openSPDF(shapefilepath='./shapefiles/ONSNeighbourhoods2012_SmallFile.shp')

outercore=openSPDF(shapefilepath = './shapefiles/outercore.shp')

labelhoods=openSPDF(shapefilepath = './shapefiles/labelhoods.shp')
labelhoods@data$names=as.character(labelhoods@data$names)
labelhoods@data$names[3]="Crestview\nMeadowlands"
labelhoods@data$names[4]="Hintonburg\nMechanicsville"
labelhoods@data$names[5]="Island\nPark"


```


Create KDE estimates of training data distrbution
```{r traindistribution, echo=FALSE}
kde.training = ptDensity(spd,outercore)
spd.yes=subset(spd,V3==1)
spd.no=subset(spd,V3==0)
kde.training.yes = ptDensity(spd.yes,outercore)
kde.training.no = ptDensity(spd.no,outercore)


```


```{r kdetrain, echo=FALSE,fig.width=4,fig.height=7,fig.cap="\\label{fig:kdetrain}a)Distribution of all GSV training images; a) all 16224 training pairs b) only training pairs that are positive for change; c) only pairs that are negative for change."}
# makeplot
#windows(width=8,height=11,xpinch=300,ypinch=300)
# Create class breaks
clstype="equal"
cint=densBreaks(kde.training,9,clstype)
cint2=densBreaks(kde.training.yes,9,clstype)
cint3=densBreaks(kde.training.no,9,clstype)
# Make color palette
my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(9)

p.plot=function(tras,cbreaks,outercore,letter,pk){
    tokmsq=1000^2
  my.palette=brewer.pal(9,'Reds')#colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)
  #par(mfg=c(1,1))
  #par(oma=c(0,0,0,4))
  plot(tras, breaks=cbreaks$brks,col = my.palette,axes=FALSE,legend=FALSE)
  plot(outercore,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
  if(pk==1) scalebar(d = 5000, xy = c(357258.223,5033798.921), type = 'bar', divs = 2, below = 'm')

  #set.panel(1,1)
    par(usr=c(0,1,0,1))
    #par(mfg=c(1,1))
  #par(oma=c(0,0,0,1))


  plot(
    tras,
    add=TRUE,
    legend.only = TRUE,
    breaks = round(cbreaks$brks*tokmsq,digits=0),
    col = my.palette,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")(s[italic('x,y')] %.% km^-2)),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
    )
  )
  #par(usr=c(0,1,0,1))
  text(0.1,0.9,letter,cex=2)
    

}

par(mfrow=c(3,1),mai=c(0,0,0,0),bty="n")
par(mfg=c(1,1))
p.plot(kde.training,cint,outercore,"A",pk=1)
# par(bg=NA)
# subplot(function(){
#   plot(ons,col='grey',border='grey')
#   plot(outercore,col=1,border=1,add=T)
# },0.5,0.3,c(0.7,0.7))#353091.8,5027886)
#par(mfrow=c(3,1))#,mai=c(0,0,0,0),bty="n")
par(mfg=c(2,1))
p.plot(kde.training.yes,cint2,outercore,"B",pk=2)
#par(mfrow=c(3,1))#,mai=c(0,0,0,0),bty="n")
par(mfg=c(3,1))
p.plot(kde.training.no,cint3,outercore,"C",pk=3)


```

The pattern of building permits and SCNN-FC-8 predictions are very similar in Figure \ref{fig:kdetrain}.

```{r kdetrain_fig, eval=TRUE,echo=FALSE,message=FALSE}
# makeplot
png("./figures/KDE_TRAINING_DISTRIB.png",units="in",width=7,height=12,res=300)
par(mfrow=c(3,1),mai=c(0.1,0,0.1,0),bty="n")

p.plot(kde.training,cint,outercore,"A",pk=1)
p.plot(kde.training.yes,cint2,outercore,"B",pk=2)
p.plot(kde.training.no,cint3,outercore,"C",pk=3)

dev.off()
```

Get oldest date for GSV imagery, youngest date and span

```{python py, echo=FALSE, eval=FALSE}
import glob
import os
basedir='f:/ottawa_image_db/'
dirlist = os.listdir(basedir)

with open("f:/models/ffxx.csv", "w") as f:
    f.write("LAT,LON,MINY,MAXY,DRANGE,NPHOTO,NYEARS\n")
    for d in dirlist:
        images = glob.glob(basedir+d+ '/*.jpg')
        if len(images)!=0:
            dlist=[]
            for image in images:
                fn=os.path.basename(image)
                dlist.append(fn[0:4])
            mx=max(dlist)
            mn=min(dlist)
            diff=int(mx)-int(mn)
            ld=len(dlist)
            lds=len(set(dlist))
            f.write("{},{},{},{},{},{}\n".format(d, mn,mx,diff,ld,lds))
            #print(dlist,min(dlist))

# All years for all images
with open("f:/models/allyearvector.csv", "w") as f:
    #f.write("LAT,LON,MINY,MAXY,DRANGE,NPHOTO,NYEARS\n")
    for d in dirlist:
        images = glob.glob(basedir+d+ '/*.jpg')
        if len(images)!=0:
            dlist=[]
            for image in images:
                fn=os.path.basename(image)
                dlist.append(fn[0:4])
                f.write("{}\n".format(fn[0:4]))
                
# locations ith a date in 2007 and a date in 2014-2016.                
with open("f:/models/ff_old_young2.csv", "w") as f:
    f.write("LAT,LON,MINY,MAXY,DRANGE,NPHOTO,NYEARS\n")
    for d in dirlist:
        images = glob.glob(basedir+d+ '/*.jpg')
        if len(images)!=0:
            dlist=[]
            fnamelist=[]
            for image in images:
                fn=os.path.basename(image)
                fnamelist.append(fn)
                dlist.append(fn[0:4])
            mx=max(dlist)
            mn=min(dlist)
            diff=int(mx)-int(mn)
            ld=len(dlist)
            lds=len(set(dlist))
            if (((mx=='2016') | (mx=='2015') | (mx=='2014')) & (mn=='2007')):
                f.write("{},{},{},{},{},{}\n".format(d, mn,mx,diff,ld,lds))
            #print(dlist,min(dlist))
```

#GSV panorama location analysis
Load GSV dates, create SPDF, assign and project.

```{r gsvdatesplot, echo=FALSE,fig.width=6,fig.height=8.5,fig.cap="\\label{fig:gsvdatesplot}Spatial distribution of the oldest date found at each location where GSV images were accessed. The grey polygon represents the study area where model predictions are made and the outer polygon represetns the extent of the full GSV dataset."}
# Get GSV date list
x = read.delim("./rproject/GSVDATESSPAN.csv",sep = ",",header = TRUE)
#names(x)=c("LAT","LONG","OLDEST","YOUNGEST","SPAN")
# Make spdf of training data duels fi
outercore$DID=rep(1,length(outercore$OBJECTID))
region <- gUnaryUnion(outercore, id = outercore@data$DID)

gsvdates = SpatialPointsDataFrame(cbind(x = x$LON, y = x$LAT), x)

# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates = spTransform(gsvdates, srMTM9)


#win.graph(8.5,11)
par(mfrow=c(5,2),mai=c(.2,0,0,0),bty="n")
for(i in seq(2007,2016,1)){
  y2007=subset(gsvdates,MINY==i)
  plot(region,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
  plot(studyarea,col='gray',add=TRUE)
  plot(y2007,pch=16,cex=0.25,add=TRUE)
  if (i==2007){  scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')}
  #plot(studyarea,add=TRUE)
  par(usr=c(0,1,0,1))
  text(0.1,0.9,i,cex=2)
}



```

```{r gsvdatesplot2, echo=FALSE,fig.width=6,fig.height=8.5,fig.cap="\\label{fig:gsvdatesplot2}Spatial distribution of the youngest date found at each location where GSV images were accessed."}
# Get GSV date list
x = read.delim("./rproject/GSVDATESSPAN.csv",sep = ",",header = TRUE)

gsvdates = SpatialPointsDataFrame(cbind(x = x$LON, y = x$LAT), x)

# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates = spTransform(gsvdates, srMTM9)


#win.graph(8.5,11)
par(mfrow=c(5,2),mai=c(.2,0,0,0),bty="n")
for(i in seq(2007,2016,1)){
  y2007=subset(gsvdates,MAXY==i)
  plot(region,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
  plot(studyarea,col='gray',add=TRUE)
  plot(y2007,pch=16,cex=0.25,add=TRUE)
  if (i==2007){  scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')}
  #plot(studyarea,add=TRUE)
  par(usr=c(0,1,0,1))
  text(0.1,0.9,i,cex=2)
}


```

```{r gsvdatesplot3, echo=FALSE,fig.width=6,fig.height=6,fig.cap="\\label{fig:gsvdatesplot3}Spatial distribution of properties that have a panorama in 2007 and also in 2014-2016."}
# Get GSV date list
x = read.delim("./rproject/ff_old_young2.csv",sep = ",",header = TRUE)

gsvdates_oldyoung = SpatialPointsDataFrame(cbind(x = x$LON, y = x$LAT), x)

# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates_oldyoung) = srNAD83

# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates_oldyoung = spTransform(gsvdates_oldyoung, srMTM9)


#win.graph(8.5,11)
par(mai=c(.2,0,0,0),bty="n")

  plot(region,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
  plot(studyarea,col='gray',add=TRUE)
  plot(gsvdates_oldyoung,pch=16,cex=0.25,add=TRUE)
  scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
  #plot(studyarea,add=TRUE)
  par(usr=c(0,1,0,1))
  #text(0.1,0.9,i,cex=2)



```

Examine date distribution

```{r histdates, echo=FALSE, fig.width=7,fig.height=3,fig.cap="\\label{fig:histdates}a) Distribution of the oldest GSV date accessed at a location; b) Distribution of all GSV image dates accessed at a location; c) Distribution of the number of years of GSV imagery at each queried location."}
par(mfrow=c(1,3),mai=c(.4,.5,.4,.1),bty="n")
hist(gsvdates$MINY,xlab="Date",ylab="Number of GSV locations",main="")
par(usr=c(0,1,0,1),xpd=NA)
text(-.15,1.1,"a)",cex=1)
av=read.delim("f:/models/allyearvector.csv",sep=",",header=F)
hist(av$V1,xlab="Date",ylab="",main="")
par(usr=c(0,1,0,1),xpd=NA)
text(-.15,1.1,"b)",cex=1)
hist(gsvdates$NYEARS,xlab="Number of years of imagery",ylab="",main="")
par(usr=c(0,1,0,1),xpd=NA)
text(-.15,1.1,"c)",cex=1)
```

Both Figure \ref{fig:histdates} and \ref{fig:gsvdatesplot} provide evidence of an approximate 2-3 year update frequency of GSV imagery. The average number of years that GSV panoramas are available is `r round(mean(gsvdates$NYEARS),digits=2)` (Figure \ref{fig:histnyears}). Both distributions also indicate that over the 10-year period there has been a decreasing overall investement in the total number of images captured at each location. That decreasing trend is suggestive of perhaps an evolving collection strategy that is informed by satellite imagery, different goals for the product or less investment in the resources Google assigns to established collections of GSV imagery.  Moreover, in order to predict back to 2007 using SCNN-FC-8, Figure \ref{fig:gsvdates} shows that only the region of our current study area contains GSV imagery in 2007.

#Results
##Model Training curves
```{python valcurves, echo=FALSE,eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:valcurves}Training and validation of SCNN-FC-8."}
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'c:/programdata/Anaconda3/Library/plugins/platforms'
import numpy as np
def plot_loss(history_saved):
    import matplotlib.pyplot as plt
    mdict = np.load(history_saved)
    mdict = mdict.tolist()
    plt.figure(41, figsize=(12, 8), dpi=150)
    loss = mdict['loss']
    val_loss = mdict['val_loss']
    epochs = range(1, len(loss) + 1)
    plt.subplot(211)
    plt.plot(epochs, loss, 'b', label='Training loss', color='r')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.subplot(212)
    acc = mdict['binary_accuracy']
    val_acc = mdict['val_binary_accuracy']
    plt.plot(epochs, acc, 'b', label='Training acc', color='r')
    plt.plot(epochs, val_acc, 'b', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()
    
mdict = np.load("./rproject/mdict14try_vgg_norm.npy")
history_continue_training="./rproject/mdict14try_vgg_norm.npy"
mdict = mdict.tolist()
print(max(mdict['val_binary_accuracy']))
plot_loss(history_continue_training)
```

##Comparison between SCNN-FC-8 predictions and building permits
```{r aname, echo=FALSE,message=FALSE}


predpts.gt2011=subset(predpts,YEAR2>=2011)

permits@bbox=studyarea@bbox
predpts.gt2011@bbox=studyarea@bbox

# Calculate KDE on training locations & convert to raster obj
kdepredict=ptDensity(predpts.gt2011,studyarea)
kdepermits=ptDensity(permits,studyarea)

# Create class breaks
cint=densBreaks(kdepredict,9,'equal')

# Make color palette
my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)
```

Plot comparison between permits and model results.

```{r comparemodelpermit, echo=FALSE,eval=TRUE, message=FALSE, fig.width=8,fig.height=4,fig.cap="\\label{fig:comparemodelpermit}Comparison of SCNN-FC-8 predictions (a) with building permits (b)."}
plot.comparemodel=function(kde1,kde2,plotintervals,colorpal,nbrpoly){
  set.panel()
  par(mfrow=c(1,2),mai=c(0,0,0,0),oma=c(0,0,0,4),bty="n")
  plot(kde1, breaks=plotintervals$brks,col = colorpal,axes=FALSE,legend=FALSE)
  plot(nbrpoly,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
  scalebar(d = 5000, 
           xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
  
  lines(c(370385.946, 375749.061),c(5033595.408,   5032711.698),lwd=1)  
  points(370385.946,  5033595.408,pch=16,col=1,cex=0.25)
  text(375749.061,5032711.698,"x",adj=c(-.5,.5))
  
  par(usr=c(0,1,0,1))
  text(0.05,0.8,"a)",cex=1)
  plot(kde2, breaks=plotintervals$brks,col = colorpal,axes=FALSE,legend=FALSE)
  plot(nbrpoly,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)


  lines(c(366410.724  , 368770.442 ),c(5035138.202 ,5029125.892),lwd=1)  
  points(368770.442,  5029125.892,pch=16,col=1,cex=0.25)
  text(366410.724,5035138.202,"x\'",adj=c(1,-0.5))

  par(usr=c(0,1,0,1))
  text(0.05,0.8,"b)",cex=1)
  
  # Add legend
  set.panel(1,1)
  par(oma=c(0,0,0,1))
  tokmsq=1000^2
  r.range <- c(minValue(kde1), maxValue(kde1))*tokmsq
  plot(
    kde1,
    legend.only = TRUE,
    breaks = round(plotintervals$brks*tokmsq,digits=0),
    col = colorpal,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")(s[italic('x,y')] %.% km^-2)),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
    )
  )
}

plot.comparemodel(kdepredict,kdepermits,cint,my.palette,nbrhoods)
```

The pattern of building permits and SCNN-FC-8 predictions are very similar in Figure \ref{fig:comparemodelpermit}.

```{r, savedensfplot, echo=FALSE, eval=TRUE, echo=FALSE,message=FALSE}
# makeplot
png("./figures/figure_pred_vs_permit.png",units="in",width=11,height=4,res=300)
plot.comparemodel(kdepredict,kdepermits,cint,my.palette,nbrhoods)
dev.off()
```

```{r differencemap, echo=FALSE,eval=TRUE, fig.width=8,fig.height=8,fig.cap="\\label{fig:differencemap}Proportional difference betweeen predicted KDE and permit KDE."}

par(bty="n")
kdepredict.n=(kdepredict-0)/(cellStats(kdepredict,stat='max')-0)
kdepermits.n=(kdepermits-0)/(cellStats(kdepermits,stat='max')-0)
kde.df=kdepredict.n-kdepermits.n

# Create class breaks
cint.d=densBreaks(kde.df,9,'equal')

# Make color palette
mypal=brewer.pal(10,"Spectral") #colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)

plot(kde.df, breaks=cint.d$brks,col = mypal,axes=FALSE,legend=FALSE)
plot(nbrhoods,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)

  lines(c(366410.724  , 368770.442 ),c(5035138.202 ,5029125.892),lwd=1)  
  points(368770.442,  5029125.892,pch=16,col=1,cex=0.25)
  text(366410.724,5035138.202,"x\'",adj=c(1,-0.5))
  lines(c(370385.946, 375749.061),c(5033595.408,   5032711.698),lwd=1)  
  points(370385.946,  5033595.408,pch=16,col=1,cex=0.25)
  text(375749.061,5032711.698,"x",adj=c(-.5,.5))
  scalebar(d = 5000, 
           xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
 # Add legend
  set.panel(1,1)
  par(oma=c(0,0,0,1))
  plot(
    kde.df,
    legend.only = TRUE,
    breaks = round(cint.d$brks,digits=3),
    col = mypal,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")[model-permit]),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
    )
  )
```

Figure \ref{fig:differencemap} illustrates the difference between the standardized intensity {lambda} of the SCNN-FC-8 predictions and building permits. The two isolagted regions of intensity in Figure \ref{fig:comparemodelpermit}, x and x', cleary stand out as the two largest diffrences between the model predictions and the building permits.   As discussed in the main text, x' is due to a large development of Landsdwon Park (https://en.wikipedia.org/wiki/Lansdowne_Park_redevelopment), and x was due to false positive detections of gentrification-like visual change because of offset/FOV issues.  IN particular, in the region denoted by x', there were a number of new homes constructed which normally would have been picked up by the model within the image sequence.  However, the sequences of GSV images in this region of x', show that the common sequence of visual changes were as such: A park, followed by construction of a large wall, removal of the large wall and construction of new housing.  The change from wall to new construction was not something that our model encountered in our training dataset and so would not see the change from a park to a wall as a gentrification like change, nor the change from a wall to a residential structure.

```{r eval=FALSE, echo=FALSE}

#make number of years by site map. and this correlation map.

temp_chl_s_nb <- raster(temp_chl_s, 1)
values(temp_chl_s_nb) <- 1:ncell(temp_chl_s)

focal_cor <- focal(
  x = temp_chl_s_nb,
  w = matrix(1, 5, 5),
  fun = function(x, y = temp_chl_s){
    cor(values(y)[x, 1], values(y)[x, 2],
        use = "na.or.complete")
  },
  filename = file.path(extraWD, "focal_cor.tif"),
  overwrite = TRUE
)
```


#SCNN-FC-8 predictions over time
```{r timeseries, echo=FALSE,eval=TRUE, message=FALSE,fig.width=6,fig.height=9,fig.cap="\\label{fig:timeseries}Comparison of SCNN-FC-8 predictions over time (a) 2009 (b) 2012 (c) 2013-2016."}
  set.panel()
plot.time=function(){
  tokmsq=1000000
  plot.t=function(predpts,year){
    # Get predictions
    predpts.gt2009=subset(predpts,YEAR2==year)
    predpts.gt2009@bbox=studyarea@bbox
    # Calculate KDE on training locations & convert to raster obj
    kde=ptDensity(predpts.gt2009,studyarea)
    return(kde*tokmsq)
  }
  
  par(mfrow=c(3,1),mai=c(0,0,0,.2),oma=c(0,0,0,4),bty="n")
  # Create class breaks
  blist=list()
  valvec=vector("numeric")
  
  for(i in c(2009,2012,2016)){
    blist[[as.character(i)]]=plot.t(predpts,i)
    #blist[[i]]
    # tvals=values(blist[[i]])
    # valvec=c(valvec,tvals)
  }

  # Make color palette
  my.palette=colorRampPalette(c(rgb(211/255,229/255,232/255,1), rgb(46/255,100/255,140/255,1)), alpha = TRUE)(10)
  lablist=list()
  lablist[['2009']]="a)"
  lablist[['2012']]="b)"
  lablist[['2016']]="c)"
  
  for(i in c('2009','2012','2016')){
    #valvec=valvec[!is.na(valvec)]*tokmsq
    #par(oma=c(0,0,0,4))
    cintx=densBreaks(blist[[i]],9,'equal')
    plot(blist[[i]], breaks=cintx$brks,col = my.palette,axes=FALSE,legend=FALSE)
    plot(nbrhoods,add=TRUE,border=rgb(144/255,144/255,144/255,1),lwd=0.5)
    if(i==2009) {
      pl=polygonsLabel(labelhoods,labelhoods@data$names,method='inpolygon',cex=0.5,polypart = 'largest')
      print(pl)
      scalebar(d = 5000, xy = c(358258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
    }
    par(usr=c(0,1,0,1))
    text(0.05,0.9,lablist[[i]],cex=1)
    #set.panel(1,1)
  #par(oma=c(0,0,0,1))
  plot(
    blist[[i]],
    legend.only = TRUE,
    add=TRUE,
    breaks = round(cintx$brks,digits=0),
    col = my.palette,
    axes = FALSE,
    legend.width = 1,
    legend.shrink = 0.45,
    horizontal = FALSE,
    axis.args = list(cex.axis = 0.5),
    legend.args = list(
      text = expression(lambda*phantom(" ")(s[italic('x,y')] %.% km^-2)),
      side = 4,
      font = 2,
      line = 2,
      cex = 0.6
      )
    )
  }
  # Add legend
 
}

plot.time()

```


```{r, savetimeplot, eval=TRUE, echo=FALSE,message=FALSE}
# makeplot
png("./figures/predovertime.png",units="in",width=6,height=9,res=300)
plot.time()
dev.off()
```




```{r excludetrain, echo=FALSE,eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:excludetrain}Comparison of SCNN-FC-8 predictions (a) using all training data (b) using only training data outside of 5 neighbourhoods"}
predex=read.csv("./rproject/fullres_replicate_onesonly_6f.csv")
predexspd = SpatialPointsDataFrame(cbind(x = as.numeric(predex$LONG), y = as.numeric(predex$LAT)), predex)

# Assign NAD83
cr = CRS("+init=epsg:4269")
proj4string(predexspd) = cr

# Reproject to MTM9 NAD83
cr = CRS("+init=epsg:32189")
predexspd = spTransform(predexspd, cr)
predexspd@bbox=studyarea@bbox
predexkde=ptDensity(predexspd,studyarea)
cint=densBreaks(predexkde,9,'equal')
plot.comparemodel(kdepredict,predexkde,cint,my.palette,nbrhoods)

```


```{r run2, echo=FALSE, eval=TRUE, fig.width=8,fig.height=4,fig.cap="\\label{fig:run2}Comparison of SCNN-FC-8 predictions (a) using first run (b) using second run"}
spdrep@bbox=studyarea@bbox
spdo@bbox=studyarea@bbox
kderun1=ptDensity(spdo,studyarea)
kderun2=ptDensity(spdrep,studyarea)
cintn=densBreaks(kderun2,9,'equal')
plot.comparemodel(kderun1,kderun2,cintn,my.palette,nbrhoods)

```

```{r echo=FALSE}
png("./figures/figure_run1_vs_run2.png",units="in",width=11,height=4,res=300)
plot.comparemodel(kderun1,kderun2,cintn,my.palette,nbrhoods)
dev.off()


```


#Example images
```{r examples, echo=FALSE,message=FALSE, fig.width=8,fig.height=11,fig.cap="\\label{fig:examples}Illustrative examples of SCNN-FC-8 predictions.  Each row represents the time series of GSV images for the unique location specified in the map plot at the end of each row. The delta symbol between any two years indicates where the SCNN-FC-8 predicted a visual change; (a to d) Normal cases of a single predicted change across the series of images at a given unique location. (e to k) represent cases where the model predicted more than one change or a false positive change wihtin the sequence.  See text for further details."}
library(imager)
#subtlechanges
  #F:\ottawa_image_db\45.395218,-75.751936
#6 commercial fov change plus occulusion
  #F:\ottawa_image_db\45.395869,-75.746973
#3 normal
  #F:\ottawa_image_db\45.385107,-75.742958
#5 normal next-door + occulusion
  #F:\ottawa_image_db\45.395435,-75.757202
#5 normal
  #F:\ottawa_image_db\45.395583,-75.757286
#6 occulusion tree
  #F:\ottawa_image_db\45.386234,-75.760761
#5 normal even with tree occulusion
  #F:\ottawa_image_db\45.385075,-75.763422
#5 normal subtle landscaping of front
  #F:\ottawa_image_db\45.387784,-75.759421
#6 landscaping front but for construction
  #F:\ottawa_image_db\45.386081,-75.751291
#6 wrong picture indicating normal
  #F:\ottawa_image_db\45.395496,-75.749797
#5 false positive due to occulusion by large tree and shadow
  #F:\ottawa_image_db\45.391192,-75.745004
#5 real plus occulusion
  #F:\ottawa_image_db\45.386595,-75.755356
#5 false positive occulusion
  #F:\ottawa_image_db\45.388473,-75.758767
#5 multiyear
  #F:\ottawa_image_db\45.342973,-75.785467
#5 normal
  #F:\ottawa_image_db\45.351836,-75.742754
#5 normal
  #F:\ottawa_image_db\45.353614,-75.742434
#5 normal
  #F:\ottawa_image_db\45.353038,-75.743813
#5 normal
  #F:\ottawa_image_db\45.352735,-75.746411
#5 normal
  #F:\ottawa_image_db\45.348013,-75.743336
#5 normal
  #F:\ottawa_image_db\45.353763,-75.747868

plotexamples=function(){
dlist=c("F:/ottawa_image_db/45.395289,-75.734107",
        "F:/ottawa_image_db/45.353038,-75.743813",
        "F:/ottawa_image_db/45.430856,-75.634009",
        "F:/ottawa_image_db/45.387784,-75.759421",
        "F:/ottawa_image_db/45.331311,-75.790179",
        "F:/ottawa_image_db/45.368548,-75.779295",
        "F:/ottawa_image_db/45.391854,-75.759665",
        "F:/ottawa_image_db/45.440927,-75.671258",
        "F:/ottawa_image_db/45.405719,-75.726039",
        "F:/ottawa_image_db/45.439506,-75.661335",
        "F:/ottawa_image_db/45.381848,-75.760526")#,
        #         "F:/ottawa_image_db/45.362226,-75.784759"       "F:/ottawa_image_db/45.391192,-75.745004","F:/ottawa_image_db/45.348997,-75.712858","F:/ottawa_image_db/45.348013,-75.743336","F:/ottawa_image_db/45.399765,-75.756267",
        #"F:/ottawa_image_db/45.398931,-75.756158")
# dlist=c("F:/ottawa_image_db/45.405719,-75.726039")
# dlist=c("F:/ottawa_image_db/45.369725,-75.628113")
# dlist=c("F:/ottawa_image_db/45.362226,-75.784759")
#F:\ottawa_image_db\45.368548,-75.779295,F:\ottawa_image_db\45.367637,-75.778784,F:\ottawa_image_db\45.397599,-75.754770,F:\ottawa_image_db\45.397651,-75.754588 F:/ottawa_image_db/45.385800,-75.746943
par(mfrow = c(11, 6), mai = c(0, .2, .2, 0))
crow=1

for(k in dlist) {
  curd = strsplit(dlist[crow], "/")[[1]][3]
  ss = subset(predptso, DIRNAME == curd)
  
  
  lf = list.files(dlist[crow],
  full.names = F,
  pattern = "\\.jpg$")
  
  tst = vector("character")
  for (i in lf) {
    tst = c(tst, strsplit(i, "_")[[1]][1])
  }
  
  # tst = data.frame(allyears = tst)
  # ssdf = data.frame(allyears = c(ss@data$YEAR1[1], ss@data$YEAR2))
  allyears = as.character(ss@data$YEAR2)
  par(mfg=c(crow,1))
  pcount=1
  for (i in lf) {
    j1 = load.image(paste(dlist[crow], "/", i, sep = ""))
    plot(j1, axes = F)
    if (pcount == 1){
      par(las=1)
      mtext(paste(letters[crow], ")"), 2, crt = 90)#mtext("(a)",3)
      par(las=0)
    }
    tt = strsplit(i, "_")[[1]][1]
    mtext(tt, 3)
    if (tt %in% allyears) {
      par(las=1)
      mtext("\u275A", 2,cex=2)#expression(bold(Delta))"\u26AB"
      par(las=0)
    }
    pcount = pcount + 1
  }
  plot(studyarea)
  xy=strsplit(strsplit(k,'/')[[1]][3],",")
  xy=SpatialPoints(cbind(x=as.numeric(xy[[1]][2]),y=as.numeric(xy[[1]][1])),proj4string=srNAD83)
  xy=spTransform(xy,srMTM9)
  plot(xy,pch=16,col=2,add=TRUE)
  crow=crow+1
}
}
plotexamples()
```



```{r echo=FALSE}
png("./figures/examples.png",units="in",width=6.5,height=10,res=300)
plotexamples()
dev.off()


```

```{r saliency, echo=FALSE, message=FALSE, fig.width=8,fig.height=11,fig.cap="\\label{fig:saliency}Class activation heat maps of \\label{fig:examples} based on the last convolutional layer in SCNN-FC-8."}
library(imager)

plotexamples2=function(){
dlist=c("F:/ottawa_image_db/45.395289,-75.734107",
        "F:/ottawa_image_db/45.353038,-75.743813",
        "F:/ottawa_image_db/45.430856,-75.634009",
        "F:/ottawa_image_db/45.387784,-75.759421",
        "F:/ottawa_image_db/45.331311,-75.790179",
        "F:/ottawa_image_db/45.368548,-75.779295",
        "F:/ottawa_image_db/45.391854,-75.759665",
        "F:/ottawa_image_db/45.440927,-75.671258",
        "F:/ottawa_image_db/45.405719,-75.726039",
        "F:/ottawa_image_db/45.439506,-75.661335",
        "F:/ottawa_image_db/45.381848,-75.760526")#,

par(mfrow = c(11, 6), mai = c(0, .2, .2, 0))
crow=1

for(k in dlist) {
  curd = strsplit(dlist[crow], "/")[[1]][3]
  ss = subset(predptso, DIRNAME == curd)
  
  
  lf = list.files(dlist[crow],
  full.names = F,
  pattern = "\\.jpg$")
  
  # tst = vector("character")
  # for (i in lf) {
  #   tst = c(tst, strsplit(i, "_")[[1]][1])
  # }
  # 
  # # tst = data.frame(allyears = tst)
  # # ssdf = data.frame(allyears = c(ss@data$YEAR1[1], ss@data$YEAR2))
  allyears = as.character(ss@data$YEAR2)
  par(mfg=c(crow,1))
  pcount=1
  for (i in lf) {
    j1 = load.image(paste("f:/fakedir", "/score", i, sep = ""))
    plot(j1, axes = F)
    if (pcount == 1){
      par(las=1)
      mtext(paste(letters[crow], ")"), 2, crt = 90)#mtext("(a)",3)
      par(las=0)
    }
    tt = strsplit(i, "_")[[1]][1]
    mtext(tt, 3)
    if (tt %in% allyears) {
      par(las=1)
      mtext("\u275A", 2,cex=2)#expression(bold(Delta))"\u26AB"
      par(las=0)
    }
    pcount = pcount + 1
  }
  plot(studyarea)
  xy=strsplit(strsplit(k,'/')[[1]][3],",")
  xy=SpatialPoints(cbind(x=as.numeric(xy[[1]][2]),y=as.numeric(xy[[1]][1])),proj4string=srNAD83)
  xy=spTransform(xy,srMTM9)
  plot(xy,pch=16,col=2,add=TRUE)
  crow=crow+1
}
}
plotexamples2()
```


```{r echo=FALSE}
png("./figures/examples_sal.png",units="in",width=6.5,height=10,res=300)
plotexamples2()
dev.off()


```


#Other stuff
```{r n, echo=FALSE,eval=FALSE}
spd2o=spdo
spd2o$X=coordinates(spd2o)[,1]
spd2o$Y=coordinates(spd2o)[,2]
spd2o=spd2o@data
```

```{python pp, echo=FALSE, eval=FALSE}
import os
import matplotlib.pyplot as plt
import pandas
import seaborn as sns
p=r.spd2o
p.to_pickle("./rproject/dummy.pkl")
#print(p.head)
print(p.X)
sns.kdeplot(p.X, p.Y, cmap="Blues", shade=True, shade_lowest=True, )
plt.show()
```



```{r thinset, echo=FALSE,eval=FALSE}
# Calculate KDE on training locations & convert to raster obj
kde = ptDensity(spd,studyarea)

kde = raster(kde)

# Extract probabilities from KDE surface
probs = extract(kde, spd)

# Add the raster probabilities to spdf after standardizing and inverting
probs[is.na(probs)]=0
maxv = max(probs, na.rm = TRUE)
minv = min(probs, na.rm = TRUE)
probs=1 - (probs - minv) / (maxv - minv)
spd@data$RASTERVALU=probs


#
# Crop and mask raster to study area
r2 <- crop(kde, extent(m4))
r3 <- mask(r2, m4)

# Plot raster
plot(r3)
plot(m3, add = TRUE, lwd = 2)

# Create a thinned dataset
idx=1:length(spd@data$RASTERVALU)
ytest=sample(idx,600, replace = FALSE, prob = spd@data$RASTERVALU/sum(spd@data$RASTERVALU))
plot(spd@data$Long,spd@data$Lat,pch=16)
x=spd@data$Long[ytest]
y=spd@data$Lat[ytest]
points(x,y,col=2)

pts=spd[ytest,]
kde=density.ppp(as.ppp(pts),eps = 50,
                  kernel = 'quartic',
                  sigma = 750)
kde=raster(kde)
r2 <- crop(kde, extent(m4))
r3 <- mask(r2, m4)
plot(r3)
plot(spd[ytest,],add=TRUE,col=2,pch=16)


library(classInt)
vals=values(r3)
vals=vals[!is.na(vals)]
cint = classIntervals(vals,n=9,style='equal')

library(RColorBrewer)
my.palette <- brewer.pal(n = 9, name = "OrRd")
plot(r3, breaks=cint$brks,col = my.palette)


```
```{r data, echo=FALSE,eval=FALSE}
library(arcgisbinding)
arc.check_product()
da=arc.open('C:/Users/laggi/Documents/ArcGIS/Default.gdb/Extract_trainin1')

da2=arc.select(da)
da3=arc.data2sp(da2)

vals=da3@data$RASTERVALU
maxv=max(vals)
minv=min(vals)

da3@data$RASTERVALU=1-(da3@data$RASTERVALU-minv)/(maxv-minv)
library(dplyr)

stest=sample_n(da3@data, 100, replace = FALSE, weight = da3@data$RASTERVALU)
plot(da3@data$Long,da3@data$Lat,pch=16)
points(stest$Long,stest$Lat,col=2)

idx=1:length(da3@data$RASTERVALU)
ytest=sample(idx,600, replace = FALSE, prob = da3@data$RASTERVALU/sum(da3@data$RASTERVALU))
plot(da3@data$Long,da3@data$Lat,pch=16)
x=da3@data$Long[ytest]
y=da3@data$Lat[ytest]
points(x,y,col=2)

pts=da3[ytest,]
plot(density.ppp(as.ppp(pts),kernel='quartic',sigma=750))

# No density
idx=1:length(da3@data$RASTERVALU)
ytest=sample(idx,500, replace = FALSE)#, prob = da3@data$RASTERVALU)
plot(da3@data$Long,da3@data$Lat,pch=16)
x=da3@data$Long[ytest]
y=da3@data$Lat[ytest]
points(x,y,col=2)

#### Density
library(raster)

tloc=arc.open('C:/Users/laggi/Documents/ArcGIS/Default.gdb/Extract_trainin2')

tloc2=arc.select(tloc)
tloc3=arc.data2sp(tloc2)
vals=tloc3@data$RASTERVALU
maxv=max(vals,na.rm=TRUE)
minv=min(vals,na.rm=TRUE)

tloc3@data$RASTERVALU=1-(tloc3@data$RASTERVALU-minv)/(maxv-minv)
r=density.ppp(as.ppp(tloc3),eps=100,kernel='quartic',sigma=750)
r=raster(r)
#,weights=tloc3@data$RASTERVALU))
m=arc.open('C:/GIST/core_multi.shp')

m2=arc.select(m)
m3=arc.data2sp(m2)
m4=spTransform(m3, CRS(proj4string(tloc3)))

r2 <- crop(r, extent(m4))
r3 <- mask(r2, m4)

plot(r3)
plot(m3, add=TRUE, lwd=2)
```


```{r, echo=FALSE,eval=FALSE}
seanpts=openSPDF(shapefilepath = 'F:/seantoIpad2018/newpoints/sample_pointsnw/sample_points.shp')

lvl=levels(seanpts@data$Label)
j=vector("numeric")
for(i in lvl){
  w=which(seanpts@data$Label==i)
  j=c(j,sample(w,2))
}
k=rep(1,length(seanpts@data$Label))
k[j]=0
seanpts$CHOICE=k
writeOGR(obj=seanpts, dsn='F:/seantoIpad2018/newpoints/sample_pointsnw', layer="newsampleptsc", driver="ESRI Shapefile")

```















