legend("bottomright",
legend = c("GSV pano.","Study area","GSV access region"),pch=c(18,NA,NA),
fill = c(NA,'grey','white'),
border=c(NA,'black','black'),
col='black',
bty = "n", # turn off the legend border
cex = .8) # decrease the font / legend size
av
q = read.delim("./rproject/allyearvector_coords.csv",sep = ",",header = FALSE)
gsvdates = SpatialPointsDataFrame(cbind(x = q[,2], y = q[,1]), q)
# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates) = srNAD83
# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates = spTransform(gsvdates, srMTM9)
gsvdates@data
head(gsvdates@data)
# Get GSV date list
q = read.delim("./rproject/allyearvector_coords.csv",sep = ",",header = FALSE)
gsvdates = SpatialPointsDataFrame(cbind(x = q[,2], y = q[,1]), q)
# Assign NAD83
srNAD83 = CRS("+init=epsg:4269")
proj4string(gsvdates) = srNAD83
# Reproject to MTM9 NAD83
srMTM9 = CRS("+init=epsg:32189")
gsvdates = spTransform(gsvdates, srMTM9)
#win.graph(8.5,11)
par(mfrow=c(5,2),mai=c(.2,0,0,0),bty="n")
for(i in seq(2007,2016,1)){
y2007=subset(gsvdates,V3==i)
plot(region,xaxt="n",yaxt="n",bty="n",ylab="",xlab="", main="", sub="")
plot(studyarea,col='gray',add=TRUE)
plot(y2007,pch=16,cex=0.25,add=TRUE)
if (i==2007){
scalebar(d = 5000, xy = c(355258.223,5033798.921), type = 'bar', divs = 2, below = 'm')
legend("bottomright",
legend = c("GSV pano.","Study area","GSV access region"),pch=c(18,NA,NA),
fill = c(NA,'grey','white'),
border=c(NA,'black','black'),
col='black',
bty = "n", # turn off the legend border
cex = .8) # decrease the font / legend size
}
#plot(studyarea,add=TRUE)
par(usr=c(0,1,0,1))
text(0.1,0.9,i,cex=2)
}
install.packages('bookdown')
10000/10
10000/100
100000/10
100000+10000
100000/110000
(100000/10)*.9
110000/10*.9
(100000/10)*.9
110000/10*.9
100000/10*.9
100000/110000
(100000/110000)*(100000/10)
j=runif(10)*100000
j
k=runif(10)*100
cbind(j,k)
data.frame(j,k)
exd=data.frame(j,k)
exd$pdens=exd$j/exd$k
exd
exd$wdens=pdens*(exd$j/sum(exd$j))
exd$wdens=exd$pdens*(exd$j/sum(exd$j))
exd
j=c(100000,10000)
k=c(10,100)
exd=data.frame(j,k)
exd
exd$pdens=exd$j/exd$k
exd
100000/10
10000/100
110000/110
10000/10100
100/10
100/110
exd$wt=exd$pdens/sum(exd$pdens)
exd
exd$wtdens=exd$pdens*exd$wt
exd
exd$wt=exd$j/sum(exd$j)
exd
exd$wtdens=exd$pdens*exd$wt
exd
exd$j
100000
10000
p2=c(3499840,901920,2076354,4032484,8307904,4145659,1984887,3903377,3822509,11789487,4919036,2388593,17799861,5149079,)
p2=c(3499840,901920,2076354,4032484,8307904,4145659,1984887,3903377,3822509,11789487,4919036,2388593,17799861,5149079,2907049,1583138,1506816,2077662,2995769,1538312,2712205,3933920)
p3=c(1783,2835,3041,2323,3914,2946,3979,3094,2951,7068,4407,2671,5309,2861,3638,3340,3434,2506,7004,5914,2844,3401)
p2/p3
p4=p2/p3
p4
d=data.frame(pop=p2,area=p4,pdens=p3)
d
d$pop/d$area
d$wdens=d$pop/sum(d$pop)*d$pdens
d
d$wdens=d$pop/sum(d$pop)*d$pop
d
d$wdens=(d$pop/sum(d$pop)*d$pop)/sum(d$pdens)
d
d$pop/sum(d$pop)
sum(d$pop/sum(d$pop))
(d$pop/sum(d$pop))*(d$pop)
(d$pop/sum(d$pop))*(d$pop/d$area)
(d$pdens/sum(d$pdens))*d$pop
d
d$pop*(d$pop/sum(d$pop))
1.05*1783
sum(d$pdens)
d$pop*sum(d$pdens)
d$pop*d$pdens/sum(d$pdens)
d$pop/(d$pop*d$pdens/sum(d$pdens))
d$pdens/sum(d$pdens)
d$pdens/sum(d$pdens)+1
d$pop/sum(d$pop)+1
attach(d)
pop/sum(pop)
pop/sum(pop)*pop
pop/sum(pop)*pdens
(pop/sum(pop)*pdens)/sum(pdens)
(pop/sum(pop)*pdens)/sum(pop)
(pop/sum(pop)*pdens)/sum(areea)
(pop/sum(pop)*pdens)/sum(area)
pop/area/sum(pop)
100000/110000
pop/sum(pop)
pop/sum(pop)*pdens
.909*100000/110
.909*100000
100000/110000
100000/110000*(100000/100)
100000/110000*(100000/10)
pop/sum(pop)*(pop/ara)
pop/sum(pop)*(pop/area)
pop/area*pop
(pop/area*pop)/sum(pop)
(pop/area)/sum(pop/area)
area
d
wdens*pdens
(sum(pop)*sum(pdens))/pop
mean(pdens)*(pop*pdens)
pdens*pop
pdens*pop/sum(pop)
d
area/pdens
(area/pdens)*pdens
(area/pdens)*pop
(area/pdens)*pop/area
pdens+(var(pdens)/pdens)
?var
exd
exd$pdens+(var(exd$pdens)/exd$pdens)
(mean(exd$pdens)*exd$j)/sum(exd$pdens)
1/sum(pop)*sum(pop)*sum(pdens)
(1/sum(pop))*(pdens*pop)
(pdens*pop)/sum(pop)
(pdens*pop)/sum(pop)+pdens
mean(pdens)
mean(pdens)*pop
mean(pdens)*pop/area
(pop/sum(pop))
(pop/sum(pop))*pdens
((pop/sum(pop))*pdens)/sum(pop)
((pop/sum(pop))*pdens)/sum(pdens
)
((pop/sum(pop))*pdens)/sum(pop/sum(pop))
library(tidyverse)
library(ggrepel)
library(scales)
setwd("C:\\Users\\laggi\\Downloads")
#source https://factfinder.census.gov/bkmk/table/1.0/en/DEC/10_SF1/GCTPH1.US05PR
df <- read_csv("DEC_10_SF1_GCTPH1.US05PR.csv", skip = 1)
#give human readable column headers
names(df) = c(
"id",
"state",
"country",
"geo_id",
"geo_id_suffix",
"geographic_area",
"county_name",
"population",
"housing_units",
"total_area",
"water_area",
"land_area",
"density_population_sqmi_land",
"density_housing_units_sqmi_land"
)
#drop puerto rico and DC. sorry guys!
df = df %>%
filter(geo_id != "0400000US72") %>%
filter(geo_id != "0500000US11001") %>%
filter(geo_id != "0400000US11")
#make a state data frame with just four facts for each state (for later joining)
sdf = df %>%
filter(!is.na(geo_id_suffix)) %>%
filter(stringr::str_length(geo_id_suffix) < 5) %>% #states have short geoids
mutate(
state = stringr::str_sub(geo_id_suffix, 1, 2),
geographic_area = stringr::str_sub(geographic_area, 16, stringr::str_length(geographic_area))
) %>%
select(state,
geographic_area,
population,
density_population_sqmi_land)
names(sdf) = c("state", "geographic_area", "state_pop", "state_density")
#clean up county data, dropping irrelevant cols
df = df %>%
filter(!is.na(geo_id_suffix)) %>%
filter(stringr::str_length(geo_id_suffix) == 5) %>% #counties have geoids of length 5
mutate(state = stringr::str_sub(geo_id_suffix, 1, 2)) %>%
select( #drop unneeded columns
-id,-country,-geo_id,-housing_units,-total_area,
-water_area,-density_housing_units_sqmi_land)
#join the state data with the county data
result = left_join(df, sdf, by = "state") %>%
group_by(state) %>%
summarise(weighted_density = round(sum(
population / state_pop * density_population_sqmi_land
), 0)) %>%
ungroup() %>%
left_join(sdf, .) %>%
arrange(-weighted_density) %>%
#mark states with weighted density 10x higher than unweighted density
mutate(highlight = weighted_density / state_density > 10)
#save clean data for posterity
write_csv(result, "result.csv")
#Make the scatterplot, Schulte style
p = ggplot(result,
aes(x = state_density, y = weighted_density, color = highlight)) +
theme_bw() +
scale_x_log10(breaks = c(1, 3, 10, 30, 100, 300, 1000, 3000, 10000),
label = comma) +
scale_y_log10(breaks = c(1, 3, 10, 30, 100, 300, 1000, 3000, 10000),
label = comma) +
geom_point() +
geom_text_repel(aes(label = geographic_area)) +
geom_abline(slope = 1) +
theme(legend.position = "none") +
labs(x = "Unweighted Population Density", y = "Weighted Population Density")
p
#ggsave(plot = p, file = "unweighted_v_weighted_density.png", height = 8, width = 8)
#make a long version of result with two rows per state
result_l = result %>%
mutate(sortval = weighted_density) %>%
gather(measure, density, state_density:weighted_density) %>%
arrange(sortval, measure) %>%
mutate(measure = factor(measure, levels = c("weighted_density", "state_density")))
# make the plot in which the rows are states sorted by weighted density
p = ggplot(result_l, aes(x = density, y = reorder(geographic_area, sortval), color = measure)) +
theme_bw() +
geom_point(size = 3) +
#connect the two measures for each state with a line
geom_line(aes(group = geographic_area), color = "black") +
scale_x_log10(breaks = c(10, 30, 100, 300, 1000, 3000, 10000),
label = comma) +
theme(legend.position = "bottom") +
labs(x = "Population density", y = "States ranked by weighted population density") +
scale_color_discrete( name = "",
breaks = c("weighted_density", "state_density"),
labels = c("Weighted Population Density", "Unweighted Population Density"))
p
#ggsave(plot = p, file = "state_v_unweighted_and_weighted_density.png", height = 8, width = 6)
library(tidyverse)
library(ggrepel)
library(scales)
install.packages(c("tidyverse","ggrepel"))
library(tidyverse)
library(ggrepel)
library(scales)
setwd("C:\\Users\\laggi\\Downloads")
#source https://factfinder.census.gov/bkmk/table/1.0/en/DEC/10_SF1/GCTPH1.US05PR
df <- read.csv("DEC_10_SF1_GCTPH1.US05PR.csv", skip = 1)
#give human readable column headers
names(df) = c(
"id",
"state",
"country",
"geo_id",
"geo_id_suffix",
"geographic_area",
"county_name",
"population",
"housing_units",
"total_area",
"water_area",
"land_area",
"density_population_sqmi_land",
"density_housing_units_sqmi_land"
)
#drop puerto rico and DC. sorry guys!
df = df %>%
filter(geo_id != "0400000US72") %>%
filter(geo_id != "0500000US11001") %>%
filter(geo_id != "0400000US11")
#make a state data frame with just four facts for each state (for later joining)
sdf = df %>%
filter(!is.na(geo_id_suffix)) %>%
filter(stringr::str_length(geo_id_suffix) < 5) %>% #states have short geoids
mutate(
state = stringr::str_sub(geo_id_suffix, 1, 2),
geographic_area = stringr::str_sub(geographic_area, 16, stringr::str_length(geographic_area))
) %>%
select(state,
geographic_area,
population,
density_population_sqmi_land)
names(sdf) = c("state", "geographic_area", "state_pop", "state_density")
#clean up county data, dropping irrelevant cols
df = df %>%
filter(!is.na(geo_id_suffix)) %>%
filter(stringr::str_length(geo_id_suffix) == 5) %>% #counties have geoids of length 5
mutate(state = stringr::str_sub(geo_id_suffix, 1, 2)) %>%
select( #drop unneeded columns
-id,-country,-geo_id,-housing_units,-total_area,
-water_area,-density_housing_units_sqmi_land)
#join the state data with the county data
result = left_join(df, sdf, by = "state") %>%
group_by(state) %>%
summarise(weighted_density = round(sum(
population / state_pop * density_population_sqmi_land
), 0)) %>%
ungroup() %>%
left_join(sdf, .) %>%
arrange(-weighted_density) %>%
#mark states with weighted density 10x higher than unweighted density
mutate(highlight = weighted_density / state_density > 10)
#save clean data for posterity
write_csv(result, "result.csv")
#Make the scatterplot, Schulte style
p = ggplot(result,
aes(x = state_density, y = weighted_density, color = highlight)) +
theme_bw() +
scale_x_log10(breaks = c(1, 3, 10, 30, 100, 300, 1000, 3000, 10000),
label = comma) +
scale_y_log10(breaks = c(1, 3, 10, 30, 100, 300, 1000, 3000, 10000),
label = comma) +
geom_point() +
geom_text_repel(aes(label = geographic_area)) +
geom_abline(slope = 1) +
theme(legend.position = "none") +
labs(x = "Unweighted Population Density", y = "Weighted Population Density")
p
#ggsave(plot = p, file = "unweighted_v_weighted_density.png", height = 8, width = 8)
#make a long version of result with two rows per state
result_l = result %>%
mutate(sortval = weighted_density) %>%
gather(measure, density, state_density:weighted_density) %>%
arrange(sortval, measure) %>%
mutate(measure = factor(measure, levels = c("weighted_density", "state_density")))
# make the plot in which the rows are states sorted by weighted density
p = ggplot(result_l, aes(x = density, y = reorder(geographic_area, sortval), color = measure)) +
theme_bw() +
geom_point(size = 3) +
#connect the two measures for each state with a line
geom_line(aes(group = geographic_area), color = "black") +
scale_x_log10(breaks = c(10, 30, 100, 300, 1000, 3000, 10000),
label = comma) +
theme(legend.position = "bottom") +
labs(x = "Population density", y = "States ranked by weighted population density") +
scale_color_discrete( name = "",
breaks = c("weighted_density", "state_density"),
labels = c("Weighted Population Density", "Unweighted Population Density"))
p
#ggsave(plot = p, file = "state_v_unweighted_and_weighted_density.png", height = 8, width = 6)
sdf
ggsave(plot = p, file = "state_v_unweighted_and_weighted_density.png", height = 8, width = 6)
result_l
install.packages("mattools")
install.packages("MATTOOLS)
install.packages("MATTOOLS")
zag.1<-mat.dissim(zagoskin, modpoll, llMod=3:4, modTaxa = 10:113, llFoss = 3:4, fosTaxa = 10:113, numAnalogs = 10, counts = T, dist.method = "inv.dist")
library(MATTOOLS)
zag.1<-mat.dissim(zagoskin, modpoll, llMod=3:4, modTaxa = 10:113, llFoss = 3:4, fosTaxa = 10:113, numAnalogs = 10, counts = T, dist.method = "inv.dist")
zag.1
zagoskin
cbind(names(zagoskin),names(modpoll))
mat.dissim
zag.1<-mat.dissim(zagoskin, modpoll, llMod=3:4, modTaxa = 10:113, llFoss = 3:4, fosTaxa = 10:113, numAnalogs = 10, counts = T, dist.method = "spherical")
zag.1
cbind(names(zagoskin),names(modpoll))
length(modpoll)
length(names(modpoll))
length(zagoskin)
names(zagoskin)
recon1 = mat.fossavg(zag.1, modEnvCol=115, fossEnvCol = 0, fossCols = 0, cutoff = 0.15, distance = -1, wmethod = "inv.dist", numanalogs = length(dObj$position[, 1]))
recon1 = mat.fossavg(dObj=zag.1, modEnvCol=115, fossEnvCol = 0, fossCols = 0, cutoff = 0.15, distance = -1, wmethod = "inv.dist", numanalogs = length(dObj$position[, 1]))
recon1 = mat.fossavg(dObj=zag.1, modEnvCol=115, fossEnvCol = 0, fossCols = 0, cutoff = 0.15, distance = -1, wmethod = "inv.dist", numanalogs = 10)
recon1
names(recon1)
recon1 = mat.fossavg(dObj=zag.1, modEnvCol=115, fossEnvCol = 0, fossCols = 0, cutoff = 0.3, distance = -1, wmethod = "inv.dist", numanalogs = 10)
recon1
mat.dissim
names(zagoskin)
mat.mc(inModern=modpoll, modTaxa = 10:113, probs = c(0.05, 0.025, 0.01, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(inModern[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(inModern=modpoll, modTaxa = 10:113, probs = c(0.05, 0.025, 0.01, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
seq(0.5,0,.05)
seq(0.5,0,-.05)
mat.mc(inModern=modpoll, modTaxa = 10:113, probs = c(0.3, 0.0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(inModern=modpoll, modTaxa = 10:113, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc
mat.mc(modpoll, modTaxa = 10:113)#, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
names(modpoll)
mat.mc(modpoll, modTaxa = 10:113,method='allpairs')#, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(modpoll, modTaxa = 10:113,method='allpairs')#, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(modpoll, modTaxa = 10:20, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(modpoll, modTaxa = 10:112, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(modpoll, modTaxa = 10:100, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(modpoll, modTaxa = 10:55, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.mc(modpoll, modTaxa = 10:25, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
qx=mat.mc(modpoll, modTaxa = 10:25, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.plot.recon(recon1,7,qx)
qx
names(qx)
mat.plot.recon()
mat.plot.recon
qx$cutoffs
qx=mat.mc(modpoll, modTaxa = 10:30, probs = c(0.3, 0.15, 0.1, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
qx$cutoffs
mat.plot.recon(recon1,7,qx)
mat.mc
qx=mat.mc(modpoll, modTaxa = 10:30, probs = c(0.05, 0.025, 0.01, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
mat.plot.recon(recon1,7,qx)
qx=mat.mc(modpoll, modTaxa = 10:100, probs = c(0.05, 0.025, 0.01, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
qx=mat.mc(modpoll, modTaxa = 10:40, probs = c(0.05, 0.025, 0.01, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
zag.1<-mat.dissim(zagoskin, modpoll, llMod=3:4, modTaxa = 10:40, llFoss = 3:4, fosTaxa = 10:113, numAnalogs = 10, counts = T, dist.method = "spherical")
recon1 = mat.fossavg(dObj=zag.1, modEnvCol=115, fossEnvCol = 0, fossCols = 0, cutoff = 0.3, distance = -1, wmethod = "inv.dist", numanalogs = 10)
qx=mat.mc(modpoll, modTaxa = 10:40, probs = c(0.05, 0.025, 0.01, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
zag.1<-mat.dissim(zagoskin, modpoll, llMod=3:4, modTaxa = 10:40, llFoss = 3:4, fosTaxa = 10:113, numAnalogs = 10, counts = T, dist.method = "spherical")
zag.1<-mat.dissim(zagoskin, modpoll, llMod=3:4, modTaxa = 10:40, llFoss = 3:4, fosTaxa = 10:40, numAnalogs = 10, counts = T, dist.method = "spherical")
recon1 = mat.fossavg(dObj=zag.1, modEnvCol=115, fossEnvCol = 0, fossCols = 0, cutoff = 0.3, distance = -1, wmethod = "inv.dist", numanalogs = 10)
qx=mat.mc(modpoll, modTaxa = 10:40, probs = c(0.05, 0.025, 0.01, 0.001), freqint = seq(0, 2, 0.02), sampleSize = length(modpoll[, 1]), method = "sawada", withReplace = T, counts = F)
qx$cutoffs
function (inrec, colAgDp = 7)#, inCritVal)
mat.plot.recon(recon1,7)#,qx)
recon1$recname
recon1$recname
attributes(recon1)
which(attributes(recon1)$names == "recname")
mpr=function (inrec, colAgDp = 7, inCritVal)
{
tmethod = attributes(inrec)$weightmethod
reccol = which(attributes(inrec)$names == "recname")
if (tmethod != "none") {
win.graph(height = 11, width = 8.5)
par(mfrow = c(2, 1))
xnt = c(inrec[, c(reccol)], inrec[, c(reccol + 1)], inrec[,
c(reccol + 2)])
plot(c(min(inrec[, colAgDp], na.rm = T), max(inrec[,
colAgDp], na.rm = T)), c(min(xnt, na.rm = T), max(xnt,
na.rm = T)), type = "n", xlab = "Age/Depth", ylab = "Environmental Value")
lines(inrec[, colAgDp], inrec[, reccol])
lines(inrec[, colAgDp], inrec[, reccol + 1], col = "blue")
lines(inrec[, colAgDp], inrec[, reccol + 2], col = "blue")
}
if (!missing(inCritVal)) {
plot(inrec[, colAgDp], inrec[, reccol + 3], type = "l",
xlab = "Age/Depth", ylab = "Dissimilarity")
abline(h = inCritVal$cutoffs$y, lwd = 2, lty = 3, col = "red")
textloc = max(inrec[, colAgDp], na.rm = T) - ((max(inrec[,
colAgDp], na.rm = T) - min(inrec[, colAgDp], na.rm = T))/50)
text(textloc, inCritVal$cutoffs$y, round(inCritVal$cutoffs$x,
3), pos = 3, col = "red")
}
}
mpr(recon1,7)#,qx)
mpr=function (inrec, colAgDp = 7, inCritVal)
{
tmethod = attributes(inrec)$weightmethod
reccol = which(attributes(inrec)$names == "recname")
if (tmethod != "none") {
#win.graph(height = 11, width = 8.5)
#par(mfrow = c(2, 1))
xnt = c(inrec[, c(reccol)], inrec[, c(reccol + 1)], inrec[,
c(reccol + 2)])
plot(c(min(inrec[, colAgDp], na.rm = T), max(inrec[,
colAgDp], na.rm = T)), c(min(xnt, na.rm = T), max(xnt,
na.rm = T)), type = "n", xlab = "Age/Depth", ylab = "Environmental Value")
lines(inrec[, colAgDp], inrec[, reccol])
lines(inrec[, colAgDp], inrec[, reccol + 1], col = "blue")
lines(inrec[, colAgDp], inrec[, reccol + 2], col = "blue")
}
}
mpr(recon1,7)#,qx)
names(recon1)
mat.fossavg()
mat.fossavg
names(zagoskin)
head(zagoskin)
head(zagoskin)
mpr(recon1,7)#,qx)
names(recon1)
library(MATTOOLS)
zag= read.csv("http://www.geomatics.uottawa.ca/mattools/zagoskin.csv")
names(zag)
critval=mat.mc(modpoll,modTaxa=10:113,sampleSize=10000, probs=c(0.1, 0.05, 0.025, 0.01, 0.001) ,counts=TRUE)
mat.plot.mc(critval) #Plot histogram and cumulative frequencies
modroc=mat.roc(modpoll,modTaxa=10:113, colClasses=116,rocEvalSeq=seq(0,2,0.02), counts=T, aucmethod='wilcox')
modroc
mat.plotroc(modroc)
